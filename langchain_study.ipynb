{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPl9ZOgEJeIhHJHKxyuRg3o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluebird702/study/blob/main/langchain_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYaGRdqvdguf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 문서는 langchain study를 하면서 정리한 노트입니다."
      ],
      "metadata": {
        "id": "xtL86y2zesDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습 준비\n",
        "colab에서 예제를 실행할 것이므로 Google AI Studio에 계정을 등록하고 Key를 얻는다. 자세한 내용은 다음 문서를 참고한다.\n",
        "\n",
        "[Gemini Key 발급받아오기](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb#scrollTo=gHYFrFPjSGNq)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ftQ7pupUexag"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 환경 테스트\n",
        "다음과 같이 테스트해보자. 공식 문서에 있는 내용을 그대로 테스트해본다.\n",
        "\n",
        "[문서 링크](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb#scrollTo=FFPBKLapSCkM)"
      ],
      "metadata": {
        "id": "W8ayGNYqGu3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google python sdk 설치\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "dAfnE_mYG92a"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 왼쪽의 열쇠 버튼에 GOOGLE_API_KEY를 등록한다음에 다음 코드를 돌려서 라이브러리를 초기화\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    display(m.name) # colab에서는 print 말고 display를 써야 wrapping된 결과를 얻을 수 있다.\n"
      ],
      "metadata": {
        "outputId": "aae3d712-06ee-4936-a236-d7080d2bba76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "RyF5Vos9G92l"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-vision-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-flash'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-flash-001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-flash-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-pro-001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-pro-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-pro-vision'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음의 코드를 테스트해보자\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "WFCoRUJ8G92m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gemini-pro를 일단 사용해본다.\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "K1lpSM2VG92m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time은 맨 첫줄에서만 동작함. 그래서 코드셀을 나눴음.\n",
        "%%time\n",
        "response = model.generate_content(\"삶의 의미가 멀까?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "outputId": "74086ace-f98e-403b-eb61-63efe9e06ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "wxqFvgqiG92m"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 150 ms, sys: 19.4 ms, total: 169 ms\n",
            "Wall time: 11.6 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> 삶의 의미는 매우 개인적이고 주관적인 것이며, 특정한 답이 없는 복잡한 문제입니다. 그러나 일반적으로 삶의 의미를 찾는 과정은 개인의 가치관, 신념, 경험과 연관되어 있습니다.\n> \n> 다음은 삶의 의미를 찾는 데 도움이 될 수 있는 몇 가지 일반적인 방법입니다.\n> \n> * **자기 반성:** 자신에게 중요한 것, 당신을 행복하게 만드는 것, 당신이 세상에 기여하고자 하는 것에 대해 숙고해 보세요.\n> * **목적 설정:** 당신에게 영감을 주고 동기를 부여하는 목표를 설정하세요. 이러한 목표는 개인적인 성장, 사회적 영향, 창의성 등 다양한 영역에 중점을 두을 수 있습니다.\n> * **열정 추구:** 당신에게 열정을 불러일으키는 활동과 pursuit에 참여하세요. 열정은 삶에 의미와 목적을 부여하는 강력한 동기가 될 수 있습니다.\n> * **관계 구축:** 가족, 친구, 공동체와 의미 있는 관계를 구축하세요. 강력한 관계는 지원, 사랑, 소속감을 제공하여 삶에 의미를 부여할 수 있습니다.\n> * **사회적 기여:** 자원봉사, 지역 사회 참여 또는 정치적 활동을 통해 사회에 기여하세요. 다른 사람들을 돕는 것은 삶에 목적 의식을 부여하고 의미를 줄 수 있습니다.\n> * **영성 탐구:** 영적 신념이나 관행을 탐구하여 삶의 더 큰 목적이나 의미를 이해하려고 노력하세요. 초월적 경험이나 의식은 삶의 의미에 대한 통찰력을 제공할 수 있습니다.\n> * **지속적인 학습:** 새로운 기술을 배우거나 새로운 관심 분야를 탐구함으로써 지속적으로 학습하는 것은 지적 자극을 제공하고 삶에 의미를 부여할 수 있습니다.\n> * **거대한 틀 고려:** 개인적인 삶을 우주와 시간의 거대한 틀 속에서 고려하세요. 이러한 관점은 삶의 일시적인 성격과 더 큰 목적 맥락에서의 의미를 이해하는 데 도움이 될 수 있습니다.\n> \n> 삶의 의미는 시간이 지남에 따라 변화하고 진화할 수 있음을 기억하는 것이 중요합니다. 개인은 다양한 경험, 도전, 통찰력을 통해 삶의 의미에 대한 이해를 심화시킬 수 있습니다."
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream으로 노출하려면 출력을 다르게 해야한다.\n",
        "%%time\n",
        "response = model.generate_content(\"삶의 의미가 멀까?\", stream=True)\n",
        "for chunk in response:\n",
        "  display(chunk.text)\n",
        "  display(\"_\"*80)"
      ],
      "metadata": {
        "outputId": "a914efec-97c9-4a6b-f8d9-7d40e5713e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "8IVW4RGvG92m"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'삶의 의미는 사람마다 달라지며, 객관적인'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' 답이 있는 질문이 아닙니다. 그러나 삶의 의미에 대해 생각하고 탐구할 수 있는 일반적인 프레임'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'워크는 다음과 같습니다.\\n\\n**목적론적 관점:**\\n* 삶에는 선험적인 목적이나 목표가 있습니다.\\n* 이 목적은 종교적 신념(하나님의 뜻), 과학적 이론(진화), 또는 개인'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'적인 가치관에 기반을 둘 수 있습니다.\\n* 삶의 의미는 이 목적을 달성하는 데 있습니다.\\n\\n**실존주의적 관점:**\\n* 삶에 내재적인 의미는 없습니다.\\n* 의미는 개인이 자신에게 부여해야 하며, 이는 책임과 선택을 수반합니다.\\n* 삶의 의미는 개인의 경험, 가치관, 행동을 통해 창출됩니다.\\n\\n**실용주의적 관점:**\\n* 삶의 의미는 실용적인 결과에 있습니다.\\n* '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'삶에는 객관적인 의미는 없지만, 우리가 행하는 것에서 의미와 만족을 찾을 수 있습니다.\\n* 삶의 의미는 개인적인 경험과 성취에 중점을 둡니다.\\n\\n**생물학적 관점:**\\n* 삶의 의미는 생존과 번식에 있습니다.\\n* 인간은 진화론적으로 생존하는 데 성공하는 것이 목표라는 경향이 있습니다.\\n* 삶의 의미는 종의 보존과 유전자 전달과 관련될 수 있습니다.\\n\\n**사회적 관점:**\\n* 삶의 의미는 사회적 관계와 공동체에 있습니다.\\n* 인간은 사회적 존재이며, 의미는 다른 사람들과 연결하고 기여하는 데서 찾을 수 있습니다.\\n* 삶의 의미는 봉사, 연대, 개인의 영향력과 관련될 수 있습니다.\\n\\n궁극적으로 삶의 의미는 개인이 정의해야 하는 문제입니다. 어떤 사람들은 삶의 목적을 찾으면서 평생을 보내는 반면, 다른 사람들은 의미를 현재의 순간과 경험에서 찾'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'습니다. 확실한 답이 없지만, 삶의 의미에 대해 생각하고 탐구하는 것은 풍부하고 보람 있는 여정이 될 수 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 173 ms, sys: 18.8 ms, total: 192 ms\n",
            "Wall time: 10.7 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예제가 openai로 되어있습니다. colab에서 테스트를 쉽게 하고 싶으니 gemini로 바꿔서 테스트해보자.\n",
        "\n",
        "일단 langchain library를 설치한다."
      ],
      "metadata": {
        "id": "17PDXdmCHzdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain 업데이트\n",
        "!pip install -U langchain langchain-community langchain-experimental langchain-core langchain-google-genai langsmith"
      ],
      "metadata": {
        "id": "4LOqUHQoHMvo",
        "outputId": "11df60d3-a78e-47e2-d2fb-d136eee691bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.1-py3-none-any.whl (973 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.5/973.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.0.59-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.2.1-py3-none-any.whl (308 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m308.5/308.5 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.5-py3-none-any.whl (34 kB)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.1.63-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.8/122.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-generativeai<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-google-genai) (0.5.4)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.4 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.4)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.4->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.23.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.9)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.64.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.6.0,>=0.5.2->langchain-google-genai) (0.6.0)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-google-genai, langchain-community, langchain-experimental\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.6 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.1 langchain-community-0.2.1 langchain-core-0.2.1 langchain-experimental-0.0.59 langchain-google-genai-1.0.5 langchain-text-splitters-0.2.0 langsmith-0.1.63 marshmallow-3.21.2 mypy-extensions-1.0.0 orjson-3.10.3 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "기본 코드 돌려봅시다!"
      ],
      "metadata": {
        "id": "v4HLXB-qHiH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# 객체 생성\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "# 물어보자.\n",
        "result = llm.invoke(\"넌 누구냐!\")\n",
        "display(f\"[답변]: {result.content}\")"
      ],
      "metadata": {
        "id": "VxCjvbg5HfTW",
        "outputId": "c0745a30-402c-4dbf-9a46-beffc0debf33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[답변]: 저는 Gemini입니다. Google에서 개발한 대규모 다국어 모델입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "요정도에서 gemini설정을 마치고 langchain 학습으로 넘어간다.\n",
        "\n",
        "langchain학습은 [테디노트님의 ebook](https://wikidocs.net/book/14314)으로 진행해본다."
      ],
      "metadata": {
        "id": "it8jBS09G92m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch01 LangChain 시작하기 노트\n"
      ],
      "metadata": {
        "id": "gBJVwwISk-7B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "프롬프트 템플릿도 한번 써보자.\n",
        "\n",
        "일단 prompt를 만든다."
      ],
      "metadata": {
        "id": "q-t4c2Pim6GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"{country}의 수도는 뭐야?\"\n",
        "\n",
        "# 템플릿 완성\n",
        "prompt = PromptTemplate.from_template(template=template)\n",
        "prompt"
      ],
      "metadata": {
        "id": "YZJEwueRne3k",
        "outputId": "a0b2f8f2-11e2-4c42-832a-fdad64159d77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], template='{country}의 수도는 뭐야?')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 다음에 prompt를 써서 요청을 날려보자"
      ],
      "metadata": {
        "id": "5YuxfaoIoXSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm) # 위에서 prompt와 llm을 만드는 코드를 실행한 후에 여기를 돌려야 한다.\n",
        "\n",
        "llm_chain.invoke({\"country\": \"대한민국\"}) # 요거는 서울"
      ],
      "metadata": {
        "id": "dpltUWLcn2aa",
        "outputId": "be19832a-dcc4-426b-a172-ff9a727dc1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '대한민국', 'text': '서울'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "apply()로 여러개의 입력도 한번에 처리가 가능하다."
      ],
      "metadata": {
        "id": "rLpu5fQpoZQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\":\"네덜란드\"}]\n",
        "\n",
        "result = llm_chain.apply(input_list)\n",
        "\n",
        "display(result)\n",
        "\n",
        "for res in result:\n",
        "  display(res[\"text\"].strip())"
      ],
      "metadata": {
        "id": "y8PLy6Qfod1T",
        "outputId": "a406948b-ff47-4217-efab-8b4eb39b241a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'text': '캔버라'}, {'text': '베이징'}, {'text': '암스테르담'}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'캔버라'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'베이징'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'암스테르담'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate()로 좀 더 자세한 추가정보를 출력할 수 있다."
      ],
      "metadata": {
        "id": "h0sF1Uweo-4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\":\"네덜란드\"}]\n",
        "\n",
        "result = llm_chain.generate(input_list)\n",
        "\n",
        "display(result)"
      ],
      "metadata": {
        "id": "ciVXZxkcpGJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰 사용량을 바로 보려면 다음과 같이 찍으면 된다고 하는데 OpenAI는 되나본데, Gemini는 아무것도 안나온다. 따로 방법을 찾아보자."
      ],
      "metadata": {
        "id": "khmIifyLqs3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.llm_output"
      ],
      "metadata": {
        "id": "Y1XNDFOrqxm1",
        "outputId": "234fe11e-e872-441d-dfbc-59848d242758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2개 이상의 변수를 템플릿 안에 정의하는 것도 가능하다."
      ],
      "metadata": {
        "id": "6tOXnzbNrQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"{area1}와 {area2}의 시차는 몇시간이야?\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "id": "7UKfHPH3rVxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "KIdklYmOrh4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(llm_chain.invoke({\"area1\": \"서울\", \"area2\": \"파리\"}))"
      ],
      "metadata": {
        "id": "zRa_8MiKrmeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [\n",
        "    {\"area1\": \"파리\", \"area2\": \"뉴욕\"},\n",
        "    {\"area1\": \"서울\", \"area2\": \"하와이\"},\n",
        "    {\"area1\": \"켄버라\", \"area2\": \"베이징\"},\n",
        "]\n",
        "\n",
        "# 반복문으로 결과 출력\n",
        "result = llm_chain.apply(input_list)\n",
        "for res in result:\n",
        "    display(res[\"text\"].strip())"
      ],
      "metadata": {
        "id": "AUlKGqUprsfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stream으로 출력도 가능하다만 OpenAI로 좀 다른거 같다. stream이란 함수를 호출해서 출력한다."
      ],
      "metadata": {
        "id": "fhMdyVyMsoNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0, #창의성\n",
        "    max_output_tokens=2048,\n",
        ")\n",
        "\n",
        "question = \"대한민국에 대해서 300자 내외로 최대한 상세히 알려줘\"\n",
        "\n",
        "for chunk in llm.stream(question):\n",
        "    display(to_markdown(chunk.content))\n",
        "    display(to_markdown(\"---\"))"
      ],
      "metadata": {
        "id": "4sR3ixAksq-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain 생성에서 LCEL(LangChain Expression Language)도 가능한지 살펴본다."
      ],
      "metadata": {
        "id": "YSQtF6uiuBB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 주어진 나라에 대하여 수도를 묻는 프롬프트 템플릿을 생성합니다.\n",
        "template = \"\"\"\n",
        "당신은 친절하게 답변해 주는 친절 봇입니다. 사용자의 질문에 [FORMAT]에 맞추어 답변해 주세요.\n",
        "답변은 항상 한글로 작성해 주세요.\n",
        "\n",
        "질문:\n",
        "{question}에 대하여 설명해 주세요.\n",
        "\n",
        "FORMAT:\n",
        "- 개요:\n",
        "- 예시:\n",
        "- 출처:\n",
        "\"\"\"\n",
        "\n",
        "template = \"\"\"\n",
        "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
        "\n",
        "상황:\n",
        "{question}\n",
        "\n",
        "FORMAT:\n",
        "- 영어 회화:\n",
        "- 한글 해석:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# OpenAI 챗모델을 초기화합니다.\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0, #창의성\n",
        "    max_output_tokens=2048,\n",
        ")\n",
        "\n",
        "# 문자열 출력 파서를 초기화합니다.\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "# 완성된 Chain 을 이용하여 country 를 '대한민국'으로 설정하여 실행합니다.\n",
        "# chain.invoke({\"country\": \"대한민국\"})\n",
        "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
      ],
      "metadata": {
        "id": "NqSS-6PhuUin",
        "outputId": "41594315-264f-454c-a99d-bffceefed274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7712ac2a9f93>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 주어진 나라에 대하여 수도를 묻는 프롬프트 템플릿을 생성합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m template = \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0m당신은\u001b[0m \u001b[0m친절하게\u001b[0m \u001b[0m답변해\u001b[0m \u001b[0m주는\u001b[0m \u001b[0m친절\u001b[0m \u001b[0m봇입니다\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m사용자의\u001b[0m \u001b[0m질문에\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFORMAT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0m에\u001b[0m \u001b[0m맞추어\u001b[0m \u001b[0m답변해\u001b[0m \u001b[0m주세요\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"question\": \"미국에서 피자 주문\"}))"
      ],
      "metadata": {
        "id": "nTiI7hbmvl5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ebook에 있는 다른 예제도 실행해본다."
      ],
      "metadata": {
        "id": "fz-4MOAHv66A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
        "\n",
        "# input 딕셔너리에 주제를 'ice cream'으로 설정합니다.\n",
        "input = {\"topic\": \"양자역학\"}\n",
        "\n",
        "# prompt 객체의 invoke 메서드를 사용하여 input을 전달하고 대화형 프롬프트 값을 생성합니다.\n",
        "prompt.invoke(input)\n",
        "\n",
        "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
        "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
        "(prompt | model).invoke(input)"
      ],
      "metadata": {
        "id": "FuE8r61Hv9uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parse_output 메서드를 사용하여 AI 모델이 생성한 메시지 문자열로 출력합니다.\n",
        "display((prompt | model | output_parser).invoke(input))"
      ],
      "metadata": {
        "id": "KBkljGX_wIvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL 인터페이스에 있는 다른 내용은 필요할 때 보면 될 것 같고, 병렬성 예제를 돌려본다."
      ],
      "metadata": {
        "id": "EDuG92JIwqy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# {country} 의 수도를 물어보는 체인을 생성합니다.\n",
        "chain1 = ChatPromptTemplate.from_template(\"{country} 의 수도는 어디야?\") | model\n",
        "\n",
        "# {country} 의 면적을 물어보는 체인을 생성합니다.\n",
        "chain2 = ChatPromptTemplate.from_template(\"{country} 의 면적은 얼마야?\") | model\n",
        "# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\n",
        "combined = RunnableParallel(capital=chain1, area=chain2)"
      ],
      "metadata": {
        "id": "gmhhArJ6w1No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.invoke(\n",
        "    {\"country\": \"대한민국\"}\n",
        ")"
      ],
      "metadata": {
        "id": "nqfeWAwVxESf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2.invoke({\"country\": \"미국\"})"
      ],
      "metadata": {
        "id": "urii-7RHxLed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 'country'에 대해 'combined' 객체의 'invoke' 메서드를 호출합니다.\n",
        "combined.invoke({\"country\": \"대한민국\"})"
      ],
      "metadata": {
        "id": "N5080IAqxQMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch07 도큐먼트 로더(Document Loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "5Bki-cRuF1we"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 01. 논문(Arxiv)"
      ],
      "metadata": {
        "id": "nkQEtQYHGQdx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arxiv는 200만편 이상이 있는 학술 논문 오픈 엑세스 아카이브입니다."
      ],
      "metadata": {
        "id": "pMUqy9OJGW-b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "먼저 Arxiv 라이브러리를 설치해보자.\n",
        "\n",
        "ArxivLoader에 대한 설명은 다음 링크를 참조하자\n",
        "\n",
        "https://pypi.org/project/arxivloader/\n"
      ],
      "metadata": {
        "id": "Wxq5T1QdKaVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. arxiv 라이브러리를 설치합니다.\n",
        "!pip install -qU arxiv\n",
        "\n",
        "# 2. arxiv.org 사이트에서 다운로드한 PDF파일을 텍스트 형식으로 변환하는 PyMuPDF 패키지를 설치합니다.\n",
        "!pip install -qU pymupdf\n"
      ],
      "metadata": {
        "id": "Y6oz9LRNGc1-",
        "outputId": "7c213655-f981-4fb9-8ed9-8369eef89632",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/81.1 kB\u001b[0m \u001b[31m758.2 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 문서를 로딩해봅시다.  "
      ],
      "metadata": {
        "id": "DGjQNMuVIBDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import ArxivLoader\n",
        "\n",
        "# ArxivLoader를 사용하여 arXiv에서 문서를 로드합니다.\n",
        "# query 매개변수는 검색할 논문의 arXiv ID이고, load_max_docs 매개변수는 로드할 최대 문서 수를 지정합니다.\n",
        "# 그 유명한 Attention Is All You Need 논문 보기\n",
        "docs = ArxivLoader(query=\"1706.03762\", load_max_docs=2).load()\n",
        "len(docs)  # 로드된 문서의 개수를 반환합니다."
      ],
      "metadata": {
        "id": "X8eI0v9-JC0K",
        "outputId": "dd15722b-51ef-4cf2-9003-685240d9a3ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metadata 출력해보기\n",
        "docs[0].metadata"
      ],
      "metadata": {
        "id": "UWmrpcSrIT0i",
        "outputId": "13526037-f5a5-4046-cd16-a4dabcd32c1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Published': '2023-08-02',\n",
              " 'Title': 'Attention Is All You Need',\n",
              " 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin',\n",
              " 'Summary': 'The dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks in an encoder-decoder configuration. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer, based\\nsolely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to be\\nsuperior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014\\nEnglish-to-German translation task, improving over the existing best results,\\nincluding ensembles by over 2 BLEU. On the WMT 2014 English-to-French\\ntranslation task, our model establishes a new single-model state-of-the-art\\nBLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction\\nof the training costs of the best models from the literature. We show that the\\nTransformer generalizes well to other tasks by applying it successfully to\\nEnglish constituency parsing both with large and limited training data.'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서의 모든 페이지 내용 중 처음 400자를 가져오기\n",
        "docs[0].page_content[:400]"
      ],
      "metadata": {
        "id": "2Mox7PvTJF9s",
        "outputId": "27df7085-2af3-41cf-dcf2-d69a216d0093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nG'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서의 글자수 보기\n",
        "len(docs[0].page_content)"
      ],
      "metadata": {
        "id": "V1EqyjirJHOH",
        "outputId": "e951b708-1bb6-490f-e2bf-f02c3389ec28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39593"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서의 페이지수 보기\n",
        "docs[0].page_content"
      ],
      "metadata": {
        "id": "jD1pIzMDKB91",
        "outputId": "d2b7e62a-bc77-4648-d0de-39460d8766f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023\\n1\\nIntroduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2\\nFigure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3\\nScaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\n√dk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\n√dk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4\\noutput values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\n∈Rdmodel×dk, W K\\ni\\n∈Rdmodel×dk, W V\\ni\\n∈Rdmodel×dv\\nand W O ∈Rhdv×dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2\\n(2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4\\nEmbeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5\\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type\\nComplexity per Layer\\nSequential\\nMaximum Path Length\\nOperations\\nSelf-Attention\\nO(n2 · d)\\nO(1)\\nO(1)\\nRecurrent\\nO(n · d2)\\nO(n)\\nO(n)\\nConvolutional\\nO(k · n · d2)\\nO(1)\\nO(logk(n))\\nSelf-Attention (restricted)\\nO(r · n · d)\\nO(1)\\nO(n/r)\\n3.5\\nPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2\\nHardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5)\\n(3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4\\nRegularization\\nWe employ three types of regularization during training:\\n7\\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU\\nTraining Cost (FLOPs)\\nEN-DE\\nEN-FR\\nEN-DE\\nEN-FR\\nByteNet [18]\\n23.75\\nDeep-Att + PosUnk [39]\\n39.2\\n1.0 · 1020\\nGNMT + RL [38]\\n24.6\\n39.92\\n2.3 · 1019\\n1.4 · 1020\\nConvS2S [9]\\n25.16\\n40.46\\n9.6 · 1018\\n1.5 · 1020\\nMoE [32]\\n26.03\\n40.56\\n2.0 · 1019\\n1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39]\\n40.4\\n8.0 · 1020\\nGNMT + RL Ensemble [38]\\n26.30\\n41.16\\n1.8 · 1020\\n1.1 · 1021\\nConvS2S Ensemble [9]\\n26.36\\n41.29\\n7.7 · 1019\\n1.2 · 1021\\nTransformer (base model)\\n27.3\\n38.1\\n3.3 · 1018\\nTransformer (big)\\n28.4\\n41.8\\n2.3 · 1019\\nResidual Dropout\\nWe apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing\\nDuring training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2\\nModel Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8\\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN\\ndmodel\\ndff\\nh\\ndk\\ndv\\nPdrop\\nϵls\\ntrain\\nPPL\\nBLEU\\nparams\\nsteps\\n(dev)\\n(dev)\\n×106\\nbase\\n6\\n512\\n2048\\n8\\n64\\n64\\n0.1\\n0.1\\n100K\\n4.92\\n25.8\\n65\\n(A)\\n1\\n512\\n512\\n5.29\\n24.9\\n4\\n128\\n128\\n5.00\\n25.5\\n16\\n32\\n32\\n4.91\\n25.8\\n32\\n16\\n16\\n5.01\\n25.4\\n(B)\\n16\\n5.16\\n25.1\\n58\\n32\\n5.01\\n25.4\\n60\\n(C)\\n2\\n6.11\\n23.7\\n36\\n4\\n5.19\\n25.3\\n50\\n8\\n4.88\\n25.5\\n80\\n256\\n32\\n32\\n5.75\\n24.5\\n28\\n1024\\n128\\n128\\n4.66\\n26.0\\n168\\n1024\\n5.12\\n25.4\\n53\\n4096\\n4.75\\n26.2\\n90\\n(D)\\n0.0\\n5.77\\n24.6\\n0.2\\n4.95\\n25.5\\n0.0\\n4.67\\n25.3\\n0.2\\n5.47\\n25.7\\n(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3\\nEnglish Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9\\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser\\nTraining\\nWSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37]\\nWSJ only, discriminative\\n88.3\\nPetrov et al. (2006) [29]\\nWSJ only, discriminative\\n90.4\\nZhu et al. (2013) [40]\\nWSJ only, discriminative\\n90.4\\nDyer et al. (2016) [8]\\nWSJ only, discriminative\\n91.7\\nTransformer (4 layers)\\nWSJ only, discriminative\\n91.3\\nZhu et al. (2013) [40]\\nsemi-supervised\\n91.3\\nHuang & Harper (2009) [14]\\nsemi-supervised\\n91.3\\nMcClosky et al. (2006) [26]\\nsemi-supervised\\n92.1\\nVinyals & Kaiser el al. (2014) [37]\\nsemi-supervised\\n92.1\\nTransformer (4 layers)\\nsemi-supervised\\n92.7\\nLuong et al. (2015) [23]\\nmulti-task\\n93.0\\nDyer et al. (2016) [8]\\ngenerative\\n93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7\\nConclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves.\\nGenerating sequences with recurrent neural networks.\\narXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11\\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12\\nAttention Visualizations\\nInput-Input Layer5\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nInput-Input Layer5\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. 허깅페이스 데이터셋"
      ],
      "metadata": {
        "id": "NMYJWaDFLPa4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "허깅 페이스 허브는 NLP, 컴퓨터 비전, 오디오 분야 등 다양한 작업에 사용될 수 있는 100개 이상의 언어로된 5000개 이상의 데이터셋을 제공한다.\n",
        "\n",
        "허깅페이스 데이터셋 로더(HuggingFaceDatasetLoader)를 써봅시다."
      ],
      "metadata": {
        "id": "mBNsaKhdLlgz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "요것도 설치해봅시다"
      ],
      "metadata": {
        "id": "239TpsdGMXPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence_transformer, faiss 없으면 에러나서 추가.\n",
        "\n",
        "!pip install datasets sentence_transformers"
      ],
      "metadata": {
        "id": "036n--nCMZdG",
        "outputId": "a3875eb9-5622-4d12-b8f4-575df3b329cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.41.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 로딩해봅시다."
      ],
      "metadata": {
        "id": "LjTywFpVMdWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import HuggingFaceDatasetLoader\n",
        "\n",
        "dataset_name = \"imdb\"  # 데이터셋 이름을 \"imdb\"로 설정합니다.\n",
        "page_content_column = \"text\"  # 페이지 내용이 포함된 열의 이름을 \"text\"로 설정합니다.\n",
        "\n",
        "# HuggingFaceDatasetLoader를 사용하여 데이터셋을 로드합니다.\n",
        "# 데이터셋 이름과 페이지 내용 열 이름을 전달합니다.\n",
        "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column)\n",
        "\n",
        "data = loader.load()  # 로더를 사용하여 데이터를 불러옵니다\n",
        "\n",
        "data[:3] # 처음 3개 요소를 봅시다."
      ],
      "metadata": {
        "id": "b4BzNqdVL9N6",
        "outputId": "7c22aaf7-4e70-473a-d87c-a8e982f353b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='\"I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \\\\\"controversial\\\\\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.\"', metadata={'label': 0}),\n",
              " Document(page_content='\"\\\\\"I Am Curious: Yellow\\\\\" is a risible and pretentious steaming pile. It doesn\\'t matter what one\\'s political views are because this film can hardly be taken seriously on any level. As for the claim that frontal male nudity is an automatic NC-17, that isn\\'t true. I\\'ve seen R-rated films with male nudity. Granted, they only offer some fleeting views, but where are the R-rated films with gaping vulvas and flapping labia? Nowhere, because they don\\'t exist. The same goes for those crappy cable shows: schlongs swinging in the breeze but not a clitoris in sight. And those pretentious indie movies like The Brown Bunny, in which we\\'re treated to the site of Vincent Gallo\\'s throbbing johnson, but not a trace of pink visible on Chloe Sevigny. Before crying (or implying) \\\\\"double-standard\\\\\" in matters of nudity, the mentally obtuse should take into account one unavoidably obvious anatomical difference between men and women: there are no genitals on display when actresses appears nude, and the same cannot be said for a man. In fact, you generally won\\'t see female genitals in an American film in anything short of porn or explicit erotica. This alleged double-standard is less a double standard than an admittedly depressing ability to come to terms culturally with the insides of women\\'s bodies.\"', metadata={'label': 0}),\n",
              " Document(page_content='\"If only to avoid making this type of film in the future. This film is interesting as an experiment but tells no cogent story.<br /><br />One might feel virtuous for sitting thru it because it touches on so many IMPORTANT issues but it does so without any discernable motive. The viewer comes away with no new perspectives (unless one comes up with one while one\\'s mind wanders, as it will invariably do during this pointless film).<br /><br />One might better spend one\\'s time staring out a window at a tree growing.<br /><br />\"', metadata={'label': 0})]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 데이터셋을 이용해서 질문에 답변해봅시다.\n",
        "\n",
        "HuggingFaceDatasetLoader를 사용해서 데이터를 로드하고, VectorstoreIndexCreator를 통해서 벡터 저장소 기반의 인덱스를 생성해봅니다."
      ],
      "metadata": {
        "id": "qrRhkQusNDOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain_community.document_loaders.hugging_face_dataset import (\n",
        "    HuggingFaceDatasetLoader,\n",
        ")\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "dataset_name = \"tweet_eval\"  # 데이터셋 이름을 \"tweet_eval\"로 설정합니다.\n",
        "page_content_column = \"text\"  # 페이지 내용이 포함된 열의 이름을 \"text\"로 설정합니다.\n",
        "name = \"stance_climate\"  # 데이터셋의 특정 부분을 식별하는 이름을 \"stance_climate\"로 설정합니다.\n",
        "\n",
        "# HuggingFaceDatasetLoader를 사용하여 데이터셋을 로드합니다.\n",
        "loader = HuggingFaceDatasetLoader(dataset_name, page_content_column, name)\n",
        "\n",
        "# 이거 문서에는 없는데 컴파일 안되서 추가합니다.\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# 로더에서 벡터 저장소 인덱스를 생성합니다.\n",
        "index = VectorstoreIndexCreator(\n",
        "    embedding=HuggingFaceEmbeddings(), # 요것도 바뀌어서 추가해줘야 합니다.\n",
        ").from_loaders([loader])\n",
        "\n",
        "query = \"What are the most used hashtag?\"  # 가장 많이 사용되는 해시태그는 무엇인가요?\n",
        "result = index.query( # 요거 사용법이 바뀌어서 llm을 꼭 넣어줘야 합니다.\n",
        "    question=query,\n",
        "    llm=ChatGoogleGenerativeAI(\n",
        "      model=\"gemini-1.5-pro-latest\", # gemini-pro로 하면 에러가 나는데 요렇게 바꾸면 됨. https://github.com/google-gemini/generative-ai-python/issues/278#issuecomment-2055815213\n",
        "      google_api_key=GOOGLE_API_KEY,\n",
        "      temperature=0, #창의성\n",
        "      max_output_tokens=204ㄱ8,\n",
        "    ),\n",
        ")\n",
        "\n",
        "result"
      ],
      "metadata": {
        "id": "rqp78sUzNTKC",
        "outputId": "fa2f284d-52fe-4b66-ce6b-7b573b78d521",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/indexes/vectorstore.py:129: UserWarning: Using InMemoryVectorStore as the default vectorstore.This memory store won't persist data. You should explicitlyspecify a vectorstore when using VectorstoreIndexCreator\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:2547: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
            "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The most used hashtag is #SemST. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 03. 웹 크롤링"
      ],
      "metadata": {
        "id": "GtiY25fgLZoj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "호오..여기는 참으로 관심이 가는 항목.\n",
        "렛츠고!"
      ],
      "metadata": {
        "id": "mVPvbT6QURgC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "필요한 것들 설치해봅시다.\n",
        "\n",
        "역시나 문서에 있는 걸로는 제대로 동작하지 않는다.\n",
        "colab이기 때문에 playwright 동작을 하기 위한 방법이 필요하다.\n",
        "\n",
        "이 [문서](https://jonghoonpark.com/2023/05/26/google-colab%EC%97%90%EC%84%9C-playwright-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0)를 참고하자."
      ],
      "metadata": {
        "id": "9n8r6vmfUiC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt install ./google-chrome-stable_current_amd64.deb\n",
        "\n",
        "!pip install nest_asyncio\n",
        "!pip install pytest-playwright\n",
        "\n",
        "!pip install -qU playwright beautifulsoup4 html2text tiktoken\n",
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "DiyPH9PWUoqM",
        "outputId": "09849e99-573f-4365-9e7d-0404383eff7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-25 15:46:29--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 172.217.214.91, 172.217.214.93, 172.217.214.190, ...\n",
            "Connecting to dl.google.com (dl.google.com)|172.217.214.91|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107624500 (103M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.3’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 102.64M   253MB/s    in 0.4s    \n",
            "\n",
            "2024-05-25 15:46:29 (253 MB/s) - ‘google-chrome-stable_current_amd64.deb.3’ saved [107624500/107624500]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "google-chrome-stable is already the newest version (125.0.6422.112-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pytest-playwright in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: playwright>=1.18 in /usr/local/lib/python3.10/dist-packages (from pytest-playwright) (1.44.0)\n",
            "Requirement already satisfied: pytest<9.0.0,>=6.2.4 in /usr/local/lib/python3.10/dist-packages (from pytest-playwright) (7.4.4)\n",
            "Requirement already satisfied: pytest-base-url<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest-playwright) (2.1.0)\n",
            "Requirement already satisfied: python-slugify<9.0.0,>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest-playwright) (8.0.4)\n",
            "Requirement already satisfied: greenlet==3.0.3 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.18->pytest-playwright) (3.0.3)\n",
            "Requirement already satisfied: pyee==11.1.0 in /usr/local/lib/python3.10/dist-packages (from playwright>=1.18->pytest-playwright) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee==11.1.0->playwright>=1.18->pytest-playwright) (4.11.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (23.2)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest<9.0.0,>=6.2.4->pytest-playwright) (2.0.1)\n",
            "Requirement already satisfied: requests>=2.9 in /usr/local/lib/python3.10/dist-packages (from pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.31.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify<9.0.0,>=6.0.0->pytest-playwright) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9->pytest-base-url<3.0.0,>=1.0.0->pytest-playwright) (2024.2.2)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 되려나..\n",
        "\n",
        "근데..이건 너무 그대로 파싱하는 것이라..이래저래 귀찮다."
      ],
      "metadata": {
        "id": "XIeJcOs9WK-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import AsyncChromiumLoader\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
        "\n",
        "\n",
        "# 크롤링할 URL 목록을 설정합니다.\n",
        "urls = [\"https://n.news.naver.com/article/011/0004345031?cds=news_media_pc\"]\n",
        "\n",
        "# AsyncChromiumLoader를 사용하여 URL에서 비동기적으로 문서를 로드합니다.\n",
        "loader = AsyncChromiumLoader(urls)\n",
        "# 로드된 문서를 가져옵니다.\n",
        "docs = loader.load()\n",
        "\n",
        "# 0번 문서의 내용 중 중간의 500자를 출력합니다.\n",
        "docs[0].page_content[6000:6500]\n",
        "\n",
        "# html2text = Html2TextTransformer()  # HTML을 텍스트로 변환하는 객체를 생성합니다.\n",
        "# docs_transformed = html2text.transform_documents(\n",
        "#     docs\n",
        "# )  # HTML 문서를 텍스트로 변환합니다.\n",
        "# print(docs_transformed[0].page_content)\n",
        "\n",
        "# # 변환 작업\n",
        "bs_transformer = BeautifulSoupTransformer()\n",
        "# HTML 문서를 변환합니다. p, li, div, a 태그의 내용을 추출합니다.\n",
        "docs_transformed = bs_transformer.transform_documents(\n",
        "    docs,\n",
        "    # tags_to_extract=[\"p\", \"li\", \"div\", \"a\"]\n",
        "    tags_to_extract=[\"div\"],\n",
        ")"
      ],
      "metadata": {
        "id": "MAOW0R54WMz1",
        "outputId": "f02f47f4-0c3d-471f-8b75-96ca6822c714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "본문 바로가기\n",
            "\n",
            "이전 페이지\n",
            "\n",
            "#  서울경제\n",
            "\n",
            "구독\n",
            "\n",
            "**언론사를 구독하면 메인** 에서 바로 볼 수 있어요!\n",
            "\n",
            "메인 뉴스판에서 서울경제 주요뉴스를  \n",
            "볼 수 있습니다. 보러가기\n",
            "\n",
            "**서울경제** 언론사 구독 해지되었습니다.\n",
            "\n",
            "  * 주요뉴스\n",
            "  * 숏폼\n",
            "  * 정치\n",
            "  * 경제\n",
            "  * 사회\n",
            "  * 생활\n",
            "  * 세계\n",
            "  * IT\n",
            "  * 사설/칼럼\n",
            "  * 신문보기\n",
            "  * 랭킹\n",
            "\n",
            "* * *\n",
            "\n",
            "_PICK_ _안내_\n",
            "\n",
            "언론사가 주요기사로  \n",
            "선정한 기사입니다. 언론사별 바로가기 닫기\n",
            "\n",
            "## 대통령실 \"연금개혁, 쫓기듯 타결 안돼…청년세대 의견 반영해야\"\n",
            "\n",
            "_입력_ 2024.05.25. 오후 6:37\n",
            "\n",
            "기사원문\n",
            "\n",
            "_박동휘 기자_\n",
            "\n",
            "  * _박동휘 기자_\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독자\n",
            "\n",
            "    0\n",
            "\n",
            "응원수\n",
            "\n",
            "    0\n",
            "\n",
            "더보기\n",
            "\n",
            "추천\n",
            "\n",
            "  * 쏠쏠정보 0\n",
            "  * 흥미진진 0\n",
            "  * 공감백배 0\n",
            "  * 분석탁월 0\n",
            "  * 후속강추 0\n",
            "\n",
            "댓글\n",
            "\n",
            "본문 요약봇\n",
            "\n",
            "**본문 요약봇도움말** 자동 추출 기술로 요약된 내용입니다. 요약 기술의 특성상 본문의 주요 내용이 제외될 수 있어, 전체 맥락을 이해하기\n",
            "위해서는 기사 본문 전체보기를 권장합니다. 닫기\n",
            "\n",
            "텍스트 음성 변환 서비스 사용하기\n",
            "\n",
            "_성별_ 남성 여성\n",
            "\n",
            "_말하기 속도_ 느림 보통 빠름\n",
            "\n",
            "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\n",
            "\n",
            "본문듣기 시작\n",
            "\n",
            "닫기\n",
            "\n",
            "글자 크기 변경하기\n",
            "\n",
            "  * 가 _1단계_ 작게\n",
            "  * 가 _2단계_ 보통\n",
            "  * 가 _3단계_ 크게\n",
            "  * 가 _4단계_ 아주크게\n",
            "  * 가 _5단계_ 최대크게\n",
            "\n",
            "SNS 보내기\n",
            "\n",
            "인쇄하기\n",
            "\n",
            "_연합뉴스_  \n",
            "[서울경제]  \n",
            "  \n",
            "대통령실은 25일 이재명 더불어민주당 대표가 기자회견을 열어 국민연금 개혁안을 21대 국회에서 처리하자고 윤석열 대통령과 국민의힘에 거듭\n",
            "요구한 데 대해 시간에 쫓기듯 졸속으로 결정해서는 안 된다고 밝혔다.  \n",
            "  \n",
            "대통령실 고위 관계자는 이날 \"보험료율과 소득대체율 수치에 대한 결정 자체도 중요하지만, 국민연금은 국민 모두의 의사를 반영해 민주적으로\n",
            "결정해 나가는 대타협의 과정과 절차도 매우 중요하다\"며 \"연금은 국민 모두의 삶에 미치는 영향이 매우 큰 사안이기 때문\"이라고 말했다.\n",
            "그러면서 \"특히 기성세대보다는 청년과 미래세대에 미치는 영향력이 엄청난 사안\"이라며 \"따라서 여야가 시간에 쫓기듯 졸속으로 결정하기보다는\n",
            "국민 전체의 의견, 특히 청년세대의 의견을 충분히 반영하여 결정하자는 것\"이라고 강조했다.  \n",
            "  \n",
            "이 고위 관계자는 \"오래 끌자는 것이 아니다\"며 \"이 대표가 여당 안을 받겠다고 양보할 의사를 이미 밝혔으므로 국민적 공감대를 형성하는 데\n",
            "그렇게 오랜 시간이 필요하지 않을 것\"이라고 덧붙였다.  \n",
            "  \n",
            "앞서 이 대표는 이날 오후 국회에서 긴급 기자회견을 열어 \"1% 때문에 지금까지 해 온 연금개혁을 무산시킬 수 없다\"며 \"여당이 제시한\n",
            "소득대체율 44%를 전적으로 수용하겠다\"고 밝혔다. 이어 정부·여당을 향해 \"윤석열 대통령께 간곡하게 부탁드린다. 연금개혁을 공언했던 약속을\n",
            "국민들이 기억하고 있다\"며 \"민주당의 제안을 받아주길 바란다. 국민의힘은 스스로 제시한 44%를 저희가 전적으로 수용했으니 바로 입법을 위한\n",
            "구체적 협의에 나서달라\"고 촉구했다.  \n",
            "  \n",
            "\n",
            "박동휘 기자(slypdh@sedaily.com)\n",
            "\n",
            "#### 기자 프로필\n",
            "\n",
            "_박동휘 기자_\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "_구독자_ _0_\n",
            "\n",
            "_응원수_ _0_\n",
            "\n",
            "  * 공포에 떠는 여군에 “예쁜데”…하마스 무장대원이 저지른 만행\n",
            "  * “UFO 비행장면 포착?”…美공군 공개한 '이 사진' 무엇\n",
            "\n",
            "#### 서울경제의 구독 많은 기자를 구독해보세요!\n",
            "\n",
            "닫기\n",
            "\n",
            "Copyright ⓒ 서울경제. All rights reserved. 무단 전재 및 재배포 금지.\n",
            "\n",
            "이 기사는 언론사에서 _정치_ 섹션으로 분류했습니다.\n",
            "\n",
            "_기사 섹션 분류 안내_\n",
            "\n",
            "기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다. 언론사는 개별 기사를 2개 이상 섹션으로 중복 분류할 수 있습니다.\n",
            "\n",
            "닫기\n",
            "\n",
            "구독\n",
            "\n",
            "**메인에서** 바로 보는 언론사 편집 뉴스 지금 바로 구독해보세요!\n",
            "\n",
            "구독중\n",
            "\n",
            "**메인에서** 바로 보는 언론사 편집 뉴스 지금 바로 확인해보세요!\n",
            "\n",
            "  * [서울포럼 2024] 기술패권 시대 생존 전략 QR 코드를 클릭하면 크게 볼 수 있어요.\n",
            "\n",
            "QR을 촬영해보세요. **[서울포럼 2024] 기술패권 시대 생존 전략**\n",
            "\n",
            "________\n",
            "\n",
            "닫기\n",
            "\n",
            "  * 서울경제 미술 전문 버티컬 미디어 '아트씽' 오픈! QR 코드를 클릭하면 크게 볼 수 있어요.\n",
            "\n",
            "QR을 촬영해보세요. **서울경제 미술 전문 버티컬 미디어 '아트씽' 오픈!**\n",
            "\n",
            "________\n",
            "\n",
            "닫기\n",
            "\n",
            "###  주요뉴스해당 언론사에서 선정하며 _언론사 페이지(아웃링크)_ 로 이동해 볼 수 있습니다.\n",
            "\n",
            "  * 박서준, 10살 연하 인플루언서와 열애설 \"사생활 확인 불가\"[공식]\n",
            "  * 강형욱 '55분 해명'에도···변호사 \"열 받아 무료 변론\", 前 직원 \"폭언 생생\"\n",
            "  * 잔디 훼손 '원천 차단', 팬들에겐 '스페셜 우비' 선물···임영웅, 오늘부터 '상암벌' 선다\n",
            "  * \"생명체 존재 가능성 있어\"···지구와 온도 비슷한 '외계 금성' 발견\n",
            "  * 황의조, 튀르키예 리그 최종전서 데뷔골\n",
            "\n",
            "**이 기사를 추천합니다**\n",
            "\n",
            "기사 추천은 24시간 내 50회까지 참여할 수 있습니다.\n",
            "\n",
            "닫기\n",
            "\n",
            "  * 쏠쏠정보 0\n",
            "  * 흥미진진 0\n",
            "  * 공감백배 0\n",
            "  * 분석탁월 0\n",
            "  * 후속강추 0\n",
            "\n",
            "**모두에게 보여주고 싶은 기사라면 _?_ beta** **이 기사를 추천합니다** 버튼을 눌러주세요.  \n",
            "집계 기간 동안 추천을 많이 받은 기사는 네이버 자동 기사배열 영역에 추천 요소로 활용됩니다. 레이어 닫기\n",
            "\n",
            "_서울경제_ 언론사홈 바로가기\n",
            "\n",
            "_언론사_ 구독 후 기사보기 __ 구독 없이 계속 보기\n",
            "\n",
            "_기자_ 구독 후 기사보기 __ 구독 없이 계속 보기\n",
            "\n",
            "##  _서울경제_ 헤드라인\n",
            "\n",
            "  * 대통령실 \"연금개혁, 쫓기듯 타결 안돼…청년세대 의견 반영해야\"\n",
            "\n",
            "대통령실은 25일 이재명 더불어민주당 대표가 기자회견을 열어 국민연금 개혁안을 21대 국회에서 처리하자고 윤석열 대통령과 국민의힘에 거듭\n",
            "요구한 데 대해 시간에 쫓기듯 졸속으로 결정해서는 안 된다고 밝혔다. 대통령실\n",
            "\n",
            "  * 이재명 \"국민 힘으로 항복시켜야\"…조국 \"8년 전 일 다시 겪을 것\"\n",
            "\n",
            "이재명 더불어민주당 대표는 25일 ‘순직 해병 진상규명 방해 및 사건 은폐 등의 진상규명을 위한 특별검사 임명법(채상병특검법)’\n",
            "재의요구권(거부권)을 행사한 윤석열 대통령을 겨냥 \"대통령이 국회 입법권을 무시하고 상\n",
            "\n",
            "  * 강형욱 '55분 해명'에도…변호사 \"열 받아 무료 변론\", 前 직원 \"폭언 생생\"\n",
            "\n",
            "직원들을 감시하기 위해 직원보다 많은 폐쇄회로TV(CCTV)를 설치하고 사내 메신저를 직원들의 동의 없이 감시했다는 의혹 등에 대해 반려동물\n",
            "훈련사 강형욱 보듬컴퍼니 대표와 그의 배우자 수잔 엘더가 24일 입을 열었\n",
            "\n",
            "  * 경복궁 낙서 테러 배후 '이팀장' 구속…사주 5개월만\n",
            "\n",
            "10대 청소년들에게 경복궁 담장에 불법 스트리밍 사이트를 연상시키는 문구를 스프레이로 낙서하도록 지시한 30대 남성이 25일 구속됐다.\n",
            "서울중앙지법 남천규 영장전담 부장판사는 이날 문화재보호법상 손상 또는 은닉 및\n",
            "\n",
            "  * “5% 확률로 살아돌아와”…금지된 박수소리 울려퍼진 英의회 무슨 일\n",
            "\n",
            "의사당 내에서 박수치는 게 허용되지 않는 영국에서 최근 모든 의원이 기립박수를 치는 일이 있었다. 박수를 받은 주인공은 보수당 하원 의원인\n",
            "크레이그 맥킨레이다. 25일(현지시간) 영국 일간 텔레그래프에 따르면 맥킨레\n",
            "\n",
            "  * 걸그룹 마신 물병이 장기자랑 상품?…대학 축제에서 생긴 일\n",
            "\n",
            "충남의 한 대학 축제에서 사회자가 초대 가수 걸그룹이 마시던 물병을 학생들에게 장기자랑 상품으로 나눠줘 논란이 일고 있다. 비판이 이어지자\n",
            "대학 측과 사회자 모두 사과문을 발표했다. 25일 해당 대학 학생회는 당시\n",
            "\n",
            "이전 뉴스들 보기\n",
            "\n",
            "1\n",
            "\n",
            "3\n",
            "\n",
            "다음 뉴스들 보기\n",
            "\n",
            "_서울경제_ 가 이 기사의 댓글 정책을 결정합니다.  안내 **댓글 정책 언론사별 선택제** 섹션별로 기사의 댓글 제공여부와 정렬방식을  \n",
            "언론사가 직접 결정합니다. 기사 섹션 정보가  \n",
            "정치/선거를 포함하는 경우 정치/선거섹션 정책이  \n",
            "적용됩니다. 단, 운영규정에 따른  \n",
            "삭제나 이용제한 조치는 네이버가 직접  \n",
            "수행합니다. 레이어 닫기\n",
            "\n",
            "**_서울경제_ 헤드라인** 더보기\n",
            "\n",
            "  * 대통령실 \"연금개혁, 쫓기듯 타결 안돼…청년세대 의견 반영해야\"\n",
            "\n",
            "5시간전\n",
            "\n",
            "  * 이재명 \"국민 힘으로 항복시켜야\"…조국 \"8년 전 일 다시 겪을 것\"\n",
            "\n",
            "4시간전\n",
            "\n",
            "  * 강형욱 '55분 해명'에도…변호사 \"열 받아 무료 변론\", 前 직원 \"폭언 생생\"\n",
            "\n",
            "8시간전\n",
            "\n",
            "  * 경복궁 낙서 테러 배후 '이팀장' 구속…사주 5개월만\n",
            "\n",
            "2시간전\n",
            "\n",
            "  * “5% 확률로 살아돌아와”…금지된 박수소리 울려퍼진 英의회 무슨 일\n",
            "\n",
            "46분전\n",
            "\n",
            "  * 걸그룹 마신 물병이 장기자랑 상품?…대학 축제에서 생긴 일\n",
            "\n",
            "31분전\n",
            "\n",
            "**네이버 AI 뉴스 알고리즘**\n",
            "\n",
            "뉴스 추천 알고리즘이 궁금하다면?\n",
            "\n",
            "**_서울경제_ 랭킹 뉴스** 오후 11시~자정까지 집계한 결과입니다. 전날 하루동안 집계한 결과입니다. 더보기 더보기\n",
            "\n",
            "  * 많이 본\n",
            "  * 댓글 많은\n",
            "\n",
            "  * _1_\n",
            "\n",
            "강형욱 '55분 해명'에도…변호사 \"열 받아 무료 변론\", 前 직원 \"폭언 생생\"\n",
            "\n",
            "8시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _2_\n",
            "\n",
            "\"모기떼·팅커벨에 캠핑도 못가겠다\"…전문가들 \"올해 곤충떼 출몰 잦을 것\"\n",
            "\n",
            "15시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _3_\n",
            "\n",
            "감정가 1억4000만 원 시흥 아파트에 92명 몰려…경기도 아파트 경매 '후끈'\n",
            "\n",
            "5시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _4_\n",
            "\n",
            "'큰놈 온다'…삼성 갤폴드6 출시 앞두고 기존 모델 '폭풍 할인'\n",
            "\n",
            "14시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _5_\n",
            "\n",
            "경복궁 낙서 테러 배후 '이팀장' 구속…사주 5개월만\n",
            "\n",
            "2시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _1_\n",
            "\n",
            "강형욱 “직원들 메신저 6개월치 밤새 봤다…아들 조롱·혐오 발언에 눈 뒤집혀”\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _2_\n",
            "\n",
            "강형욱 '55분 해명'에도…변호사 \"열 받아 무료 변론\", 前 직원 \"폭언 생생\"\n",
            "\n",
            "8시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _3_\n",
            "\n",
            "앞치마 두르고 계란말이 만든 尹, 용산서 기자들과 김치찌개 만찬\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _4_\n",
            "\n",
            "이재명 \"소득대체율 44% 수용…尹, 민주당 제안 받아달라\"\n",
            "\n",
            "10시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _5_\n",
            "\n",
            "술 냄새 풀풀 나도 음주운전 무혐의?…김호중이 쏘아올린 '위드마크'란[폴리스라인]\n",
            "\n",
            "13시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _1_\n",
            "\n",
            "강형욱 '55분 해명'에도…변호사 \"열 받아 무료 변론\", 前 직원 \"폭언 생생\"\n",
            "\n",
            "8시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _2_\n",
            "\n",
            "\"모기떼·팅커벨에 캠핑도 못가겠다\"…전문가들 \"올해 곤충떼 출몰 잦을 것\"\n",
            "\n",
            "15시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _3_\n",
            "\n",
            "감정가 1억4000만 원 시흥 아파트에 92명 몰려…경기도 아파트 경매 '후끈'\n",
            "\n",
            "5시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _4_\n",
            "\n",
            "'큰놈 온다'…삼성 갤폴드6 출시 앞두고 기존 모델 '폭풍 할인'\n",
            "\n",
            "14시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _5_\n",
            "\n",
            "경복궁 낙서 테러 배후 '이팀장' 구속…사주 5개월만\n",
            "\n",
            "2시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _1_\n",
            "\n",
            "강형욱 “직원들 메신저 6개월치 밤새 봤다…아들 조롱·혐오 발언에 눈 뒤집혀”\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _2_\n",
            "\n",
            "강형욱 '55분 해명'에도…변호사 \"열 받아 무료 변론\", 前 직원 \"폭언 생생\"\n",
            "\n",
            "8시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _3_\n",
            "\n",
            "앞치마 두르고 계란말이 만든 尹, 용산서 기자들과 김치찌개 만찬\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _4_\n",
            "\n",
            "이재명 \"소득대체율 44% 수용…尹, 민주당 제안 받아달라\"\n",
            "\n",
            "10시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * _5_\n",
            "\n",
            "술 냄새 풀풀 나도 음주운전 무혐의?…김호중이 쏘아올린 '위드마크'란[폴리스라인]\n",
            "\n",
            "13시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "**__함께 볼만한 기자** 안내\n",
            "\n",
            "최근 일주일 이내 업데이트된 기자 중에서 무작위 순서로 노출합니다.\n",
            "\n",
            "닫기\n",
            "\n",
            "  * 비슷한 주제\n",
            "  * 구독자 많은\n",
            "\n",
            "  * 서소정 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "서소정 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "대통령실 \"연금개혁, 시간 쫓기듯 결정보다 국민의견 반영해 결정\"\n",
            "\n",
            "아시아경제\n",
            "\n",
            "5시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김세희 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김세희 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "원유철 전 대표 `평택항 신생매립지 되찾기` 공로로 감사패 받아\n",
            "\n",
            "디지털타임스\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 장하얀 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "장하얀 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "‘첫목회’ 박상수 “자발적 팬덤이 한동훈 전당대회로 불러내고 있어”[중립기어]\n",
            "\n",
            "동아일보\n",
            "\n",
            "6시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 장관석 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "장관석 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "정호성 대통령실 합류에 野 “탄핵 대비냐”\n",
            "\n",
            "동아일보\n",
            "\n",
            "22시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 박정훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "박정훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "도담소 전면 개방한 김동연 \"서로 믿고 더불어 사는 공동체 만들겠다\"\n",
            "\n",
            "오마이뉴스\n",
            "\n",
            "6시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김기태 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김기태 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "'국정농단 실형' 비서관 발탁…야권서 비판 잇따라\n",
            "\n",
            "SBS\n",
            "\n",
            "16시간전\n",
            "\n",
            "_재생하기_\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김덕훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김덕훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "북러, 과학기술 협력 논의…모스크바서 과기분과위 개최\n",
            "\n",
            "KBS\n",
            "\n",
            "3일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이범수 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이범수 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "민주 “대통령실, 李 ‘연금개혁 회담’ 제안 사실상 거절”\n",
            "\n",
            "서울신문\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 노민호 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "노민호 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "조태열 외교장관, 美 랜드연구소 대표단 만나 '한미동맹 발전' 논의\n",
            "\n",
            "뉴스1\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이준규 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이준규 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "법사위원장 정청래? 추미애?…개딸에 휘둘리는 민주당\n",
            "\n",
            "노컷뉴스\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 조권형 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "조권형 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "대통령실 “비서관실별로 정책 현실성 사전 점검할 것”\n",
            "\n",
            "동아일보\n",
            "\n",
            "2일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 나윤석 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "나윤석 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "이재명 “국민연금 소득대체율 44~45% 사이 열려있어” … 연일 용산 결단 압박\n",
            "\n",
            "문화일보\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김종우 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김종우 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "美하원, 트럼프 압박에도…\"주한미군 2만8500명 유지\"\n",
            "\n",
            "한국경제\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 심은석 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "심은석 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "[결혼]이윤범군 김현아양\n",
            "\n",
            "강원일보\n",
            "\n",
            "5일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김영수 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김영수 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "尹 지지율 5주간 24%(갤럽) ...'尹과 갈등' 한동훈의 선택은? [앵커리포트]\n",
            "\n",
            "YTN\n",
            "\n",
            "1일전\n",
            "\n",
            "_재생하기_\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김경훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김경훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "'버닝썬' 때문이었나…구하라 사망 50일 뒤 '금고 절도사건' 재조명\n",
            "\n",
            "서울경제\n",
            "\n",
            "8시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 최기성 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "최기성 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“우리도 한국의 기업시민입니다”…‘더불어 삶’ 폭스바겐그룹 우리재단 출범\n",
            "\n",
            "매일경제\n",
            "\n",
            "2일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이상규 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이상규 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“제거 수술했는데 1년 후 재발판정”…암투병 고백한 ‘파묘’ 여배우\n",
            "\n",
            "매일경제\n",
            "\n",
            "7시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 권준영 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "권준영 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "이준석에 고개 숙인 개혁신당 노예슬 “李 당선인에 미친 피해 생각해서라도…”\n",
            "\n",
            "디지털타임스\n",
            "\n",
            "17시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 강영운 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "강영운 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“여보, 그 여배우랑 사귀어봐”···남편 불륜을 응원한 여자의 사연 [사색(史色)]\n",
            "\n",
            "매일경제\n",
            "\n",
            "14시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 류영상 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "류영상 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "‘5개월 만에 잡힌’ 경복궁 10대 낙서 배후 ‘이 팀장’ 결국 구속\n",
            "\n",
            "매일경제\n",
            "\n",
            "1시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 조성신 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "조성신 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“한도 200% 땡겼다”…대전 전세사기 피해 80%, 이곳서 대출받았다\n",
            "\n",
            "매일경제\n",
            "\n",
            "7시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이보람 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이보람 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "음주뺑소니에 거짓말까지…김호중-소속사 대표 줄줄이 구속\n",
            "\n",
            "중앙일보\n",
            "\n",
            "1일전\n",
            "\n",
            "_재생하기_\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 홍민성 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "홍민성 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "\"김호중·강형욱 왜 김건희 나오자 터지나\"…음모론 '술렁' [이슈+]\n",
            "\n",
            "한국경제\n",
            "\n",
            "15시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 문지연 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "문지연 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "‘올해 1호 태풍’ 필리핀서 발달 중... 우리나라 영향은?\n",
            "\n",
            "조선일보\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이지희 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이지희 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "김호중, 벤틀리 타기 직전 비틀대는 모습 다 찍혔다\n",
            "\n",
            "데일리안\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 최재원 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "최재원 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "신동빈 '콘텐츠 강화 전략' 통했다 … 포켓몬타운에 400만명 몰려\n",
            "\n",
            "매일경제\n",
            "\n",
            "2일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이미나 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이미나 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "\"김호중 위해 힘없는 막내 매니저 처벌받아도 되나\" 판사의 질책\n",
            "\n",
            "한국경제\n",
            "\n",
            "23시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 박태훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "박태훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "박훈 변호사 \"강형욱, CCTV 감시용 아냐?…열받아서, 姜의 직원 무료 변론\"\n",
            "\n",
            "뉴스1\n",
            "\n",
            "15시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 윤현주 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "윤현주 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "주가 40% 폭등했다가 20% 하락…개미 '진땀'나게 한 이 종목 [윤현주의 主食이 주식]\n",
            "\n",
            "한국경제\n",
            "\n",
            "17시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 서소정 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "서소정 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "대통령실 \"연금개혁, 시간 쫓기듯 결정보다 국민의견 반영해 결정\"\n",
            "\n",
            "아시아경제\n",
            "\n",
            "5시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김세희 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김세희 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "원유철 전 대표 `평택항 신생매립지 되찾기` 공로로 감사패 받아\n",
            "\n",
            "디지털타임스\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 장하얀 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "장하얀 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "‘첫목회’ 박상수 “자발적 팬덤이 한동훈 전당대회로 불러내고 있어”[중립기어]\n",
            "\n",
            "동아일보\n",
            "\n",
            "6시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 장관석 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "장관석 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "정호성 대통령실 합류에 野 “탄핵 대비냐”\n",
            "\n",
            "동아일보\n",
            "\n",
            "22시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 박정훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "박정훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "도담소 전면 개방한 김동연 \"서로 믿고 더불어 사는 공동체 만들겠다\"\n",
            "\n",
            "오마이뉴스\n",
            "\n",
            "6시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김기태 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김기태 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "'국정농단 실형' 비서관 발탁…야권서 비판 잇따라\n",
            "\n",
            "SBS\n",
            "\n",
            "16시간전\n",
            "\n",
            "_재생하기_\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김덕훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김덕훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "북러, 과학기술 협력 논의…모스크바서 과기분과위 개최\n",
            "\n",
            "KBS\n",
            "\n",
            "3일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이범수 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이범수 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "민주 “대통령실, 李 ‘연금개혁 회담’ 제안 사실상 거절”\n",
            "\n",
            "서울신문\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 노민호 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "노민호 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "조태열 외교장관, 美 랜드연구소 대표단 만나 '한미동맹 발전' 논의\n",
            "\n",
            "뉴스1\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이준규 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이준규 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "법사위원장 정청래? 추미애?…개딸에 휘둘리는 민주당\n",
            "\n",
            "노컷뉴스\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 조권형 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "조권형 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "대통령실 “비서관실별로 정책 현실성 사전 점검할 것”\n",
            "\n",
            "동아일보\n",
            "\n",
            "2일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 나윤석 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "나윤석 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "이재명 “국민연금 소득대체율 44~45% 사이 열려있어” … 연일 용산 결단 압박\n",
            "\n",
            "문화일보\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김종우 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김종우 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "美하원, 트럼프 압박에도…\"주한미군 2만8500명 유지\"\n",
            "\n",
            "한국경제\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 심은석 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "심은석 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "[결혼]이윤범군 김현아양\n",
            "\n",
            "강원일보\n",
            "\n",
            "5일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김영수 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김영수 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "尹 지지율 5주간 24%(갤럽) ...'尹과 갈등' 한동훈의 선택은? [앵커리포트]\n",
            "\n",
            "YTN\n",
            "\n",
            "1일전\n",
            "\n",
            "_재생하기_\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 김경훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "김경훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "'버닝썬' 때문이었나…구하라 사망 50일 뒤 '금고 절도사건' 재조명\n",
            "\n",
            "서울경제\n",
            "\n",
            "8시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 최기성 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "최기성 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“우리도 한국의 기업시민입니다”…‘더불어 삶’ 폭스바겐그룹 우리재단 출범\n",
            "\n",
            "매일경제\n",
            "\n",
            "2일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이상규 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이상규 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“제거 수술했는데 1년 후 재발판정”…암투병 고백한 ‘파묘’ 여배우\n",
            "\n",
            "매일경제\n",
            "\n",
            "7시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 권준영 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "권준영 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "이준석에 고개 숙인 개혁신당 노예슬 “李 당선인에 미친 피해 생각해서라도…”\n",
            "\n",
            "디지털타임스\n",
            "\n",
            "17시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 강영운 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "강영운 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“여보, 그 여배우랑 사귀어봐”···남편 불륜을 응원한 여자의 사연 [사색(史色)]\n",
            "\n",
            "매일경제\n",
            "\n",
            "14시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 류영상 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "류영상 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "‘5개월 만에 잡힌’ 경복궁 10대 낙서 배후 ‘이 팀장’ 결국 구속\n",
            "\n",
            "매일경제\n",
            "\n",
            "1시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 조성신 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "조성신 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "“한도 200% 땡겼다”…대전 전세사기 피해 80%, 이곳서 대출받았다\n",
            "\n",
            "매일경제\n",
            "\n",
            "7시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이보람 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이보람 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "음주뺑소니에 거짓말까지…김호중-소속사 대표 줄줄이 구속\n",
            "\n",
            "중앙일보\n",
            "\n",
            "1일전\n",
            "\n",
            "_재생하기_\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 홍민성 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "홍민성 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "\"김호중·강형욱 왜 김건희 나오자 터지나\"…음모론 '술렁' [이슈+]\n",
            "\n",
            "한국경제\n",
            "\n",
            "15시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 문지연 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "문지연 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "‘올해 1호 태풍’ 필리핀서 발달 중... 우리나라 영향은?\n",
            "\n",
            "조선일보\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이지희 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이지희 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "김호중, 벤틀리 타기 직전 비틀대는 모습 다 찍혔다\n",
            "\n",
            "데일리안\n",
            "\n",
            "1일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 최재원 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "최재원 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "신동빈 '콘텐츠 강화 전략' 통했다 … 포켓몬타운에 400만명 몰려\n",
            "\n",
            "매일경제\n",
            "\n",
            "2일전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 이미나 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "이미나 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "\"김호중 위해 힘없는 막내 매니저 처벌받아도 되나\" 판사의 질책\n",
            "\n",
            "한국경제\n",
            "\n",
            "23시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 박태훈 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "박태훈 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "박훈 변호사 \"강형욱, CCTV 감시용 아냐?…열받아서, 姜의 직원 무료 변론\"\n",
            "\n",
            "뉴스1\n",
            "\n",
            "15시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "  * 윤현주 기자\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독해주셔서 감사합니다\n",
            "\n",
            "윤현주 기자의 기사는  \n",
            "언론사별에서 볼 수 있습니다\n",
            "\n",
            "닫기\n",
            "\n",
            "언론사도 함께 구독해 보세요.\n",
            "\n",
            "구독\n",
            "\n",
            "언론사를 함께 구독중입니다.\n",
            "\n",
            "주가 40% 폭등했다가 20% 하락…개미 '진땀'나게 한 이 종목 [윤현주의 主食이 주식]\n",
            "\n",
            "한국경제\n",
            "\n",
            "17시간전\n",
            "\n",
            "더보기\n",
            "\n",
            "새로보기\n",
            "\n",
            "## 함께 볼만한 뉴스\n",
            "\n",
            "안내\n",
            "\n",
            "이 기사를 본 이용자들이 함께 많이 본 기사, 해당 기사와 유사한 기사, 관심 기사 등을 자동 추천합니다\n",
            "\n",
            "닫기\n",
            "\n",
            "  * 이재명 \"소득대체율 44% 수용…尹, 민주당 제안 받아달라\"\n",
            "\n",
            "더불어민주당 이재명 대표가 25일 국민연금 개혁 논의와 관련해 \"꼭 해야 할 일인데 시간은 없으니 불가피하게 민주당이 다 양보하겠다. 여당이\n",
            "제시한 소득대체율 44%를 전적으로 수용하겠다\"고 밝혔다. 이 대표는 이날\n",
            "\n",
            "  * _재생하기_ _재생시간_ 01:56\n",
            "\n",
            "서울대생들도 \"의대 갈래요\"…이공계는 \"연구 경쟁력 우려\"\n",
            "\n",
            "서울 학원가에서 이른바 N수생과 반수생들을 상대로 한 입시 설명회가 열렸습니다. 내년도 의대 정원이 1천500여 명 늘어나는 것으로 확정된\n",
            "뒤 처음 열리는 거였죠. 어떤 이야기들이 나왔는지, 김지욱 기자가 현장 다녀\n",
            "\n",
            "  * 與, 野 ‘채상병특검법’ 집회에 “죽음 정치에 이용·탄핵 바람몰이”\n",
            "\n",
            "국민의힘은 25일 더불어민주당 등 범야권이 ‘채상병특검법’ 통과를 촉구하는 장외집회를 여는 것에 대해 죽음을 정치에 이용하는 ‘윤석열 대통령\n",
            "탄핵 바람몰이’라고 비판했다. 정광재 대변인은 논평에서 \"민주당이 대규모\n",
            "\n",
            "  * 與, 野 연금개혁 주장에 \"특검법 처리 희생량으로 삼으려 해\"\n",
            "\n",
            "국민의힘은 오늘(25일) 더불어민주당 이재명 대표가 21대 국회 연금 개혁안 처리를 촉구하는 데 대해 '정치적 꼼수'라며 비판했습니다.\n",
            "장동혁 원내수석대변인은 논평에서 \"민주당이 국민의 노후와 미래 세대에 막대한 영\n",
            "\n",
            "  * '음주운전' 숨기려 '조직적 증거인멸', 결국 김호중 발목 잡았다[체크리스트]\n",
            "\n",
            "우리 사회에서 논란이 되거나 쟁점이 되는 예민한 현안을 점검하는 고정물입니다. 확인·점검 사항 목록인 '체크리스트'를 만들 듯, 우리 사회의\n",
            "과제들을 꼼꼼히 살펴보겠습니다. '음주 뺑소니' 논란을 연신 부인하며 여론\n",
            "\n",
            "  * 이재명 \"국민 힘으로 항복시켜야\"…조국 \"8년 전 일 다시 겪을 것\"\n",
            "\n",
            "이재명 더불어민주당 대표는 25일 ‘순직 해병 진상규명 방해 및 사건 은폐 등의 진상규명을 위한 특별검사 임명법(채상병특검법)’\n",
            "재의요구권(거부권)을 행사한 윤석열 대통령을 겨냥 \"대통령이 국회 입법권을 무시하고 상\n",
            "\n",
            "  * 국민의힘, 野 '채상병특검법' 집회에 \"죽음을 정치에 이용, 떼쓰기 정치\"\n",
            "\n",
            "국민의힘이 야당과 시민단체의 '채 상병 특검법 통과 촉구 장외집회'에 대해 \"떼쓰기 정치\"라고 비판했다. 정광재 국민의힘 대변인은 25일\n",
            "논평을 통해 \"더불어민주당에 법과 원칙이 사라진 지 이미 오래\"라며 \"순직 해\n",
            "\n",
            "  * \"초딩 때 찍었던 영상 누가 볼까 아찔\" 흑역사 지우는 중고딩들\n",
            "\n",
            "부끄러운 과거의 모습을 지울 수 있었어요.\" \"비밀번호를 잃어버린 계정에 다시 접속하지 않고도 게시물을 삭제할 수 있었어요.\" \"개인정보가\n",
            "노출되고 있다는 불안감을 해소했어요.\" 시행 1년을 맞은 정부 '지우개'서\n",
            "\n",
            "  * 대통령실 \"연금개혁, 쫓기듯 타결 말고 22대 국회서 대타협해야\"\n",
            "\n",
            "더불어민주당 이재명 대표가 기자회견을 열어 국민연금 개혁안을 21대 국회에서 처리하자고 윤석열 대통령과 국민의힘에 거듭 요구한 데 대해\n",
            "대통령실 부정적 입장을 밝혔습니다. 대통령실 고위 관계자는 오늘(25일) 연합뉴\n",
            "\n",
            "  * 여야 원내지도부 주말 회동 취소…'원 구성 협상' 평행선\n",
            "\n",
            "22대 국회 원 구성 협상을 위한 여야 원내지도부의 주말 회동이 취소됐습니다. 국민의힘 추경호 원내대표와 배준영 원내수석부대표, 더불어민주당\n",
            "박찬대 원내대표와 박성준 원내수석부대표는 오늘(25일) 오후 시내 모처에서\n",
            "\n",
            "  * 지하철 좌석 4개 차지한 ‘문신남’…“30분 퍼질러 자더라”\n",
            "\n",
            "서울 지하철 6호선 좌석을 차지하고 드러누운 ‘쩍벌’ 남성의 모습이 공분을 사고 있다. 25일 직장인 익명 커뮤니티 ‘블라인드’에는 “6호선\n",
            "병X 같은 문신남 박제”란 제목의 글이 올라왔다. 글에 게재된 사진에는 한\n",
            "\n",
            "  * 홍준표 \"채상병 특검은 과한 정치공세…찬성하는 여당 의원 한심\"\n",
            "\n",
            "홍준표 대구시장은 25일 채상병 순직사고 특검과 관련해 “대통령 탄핵 운운하는 특검 시도는 과도한 정치공세로 보인다”고 말했다. 홍 시장은\n",
            "자신의 페이스북 글에서 “채상병의 순직은 가슴 아프고 유족들의 슬픔은 국민\n",
            "\n",
            "  * 野, 전세사기특별법도 강행…21대 막판 또 다른 화약고\n",
            "\n",
            "더불어민주당이 28일 국회 본회의에서 '전세사기특별법 개정안' 강행 처리를 예고하면서 21대 국회 마지막까지 여야가 갈등을 이어갈 전망이다.\n",
            "여당은 개정안에 반대하는 입장이라 윤석열 대통령이\n",
            "\n",
            "  * [와이파일] 이근 대위가 말하는 우크라이나…F-16, 전황 바꿀까?\n",
            "\n",
            "이근 예비역 대위는 여러 가지 논란을 몰고 다니는 인물이지만, 군사 분야 전문가란 점에서는 의문의 여지가 없습니다. 우크라이나 종군 기자로\n",
            "취재를 마치고 돌아온 이후 현지 취재를 통해 알게 된 재미한인 자원봉사자를\n",
            "\n",
            "  * '채상병 특검' 표단속에 與 사활…이틀째 편지, 전직 원내대표도 동참\n",
            "\n",
            "국민의힘 지도부가 오는 28일 '해병대 채상병 사망사건 외압 의혹 특별검사법'(채상병 특검법)의 국회 본회의 재표결을 앞두고 이탈표 방지에\n",
            "사활을 걸고 있다. 추경호 국민의힘 원내대표는 당 소속 의원들에 이어 당원들\n",
            "\n",
            "  * 고민정, ‘세금 폭탄’ 종부세 폐지 주장에… 당내 \"국민의힘으로 가라\"\n",
            "\n",
            "더불어민주당 고민정 최고위원이 종합부동산세 폐지를 주장하자 당내 비난이 쏟아지고 있다. 최민희 당선자를 비롯한 야권 인사들은 고 최고위원을\n",
            "향해 “보수 언론에 동화된 생각” 이라며 공개적으로 비판했다. 고 최고위원\n",
            "\n",
            "  * \"부작용 심해서\" …자궁 내 피임장치 혼자 빼 버린 女, 괜찮을까?\n",
            "\n",
            "자궁 내 피임장치를 스스로 제거한 여성 사연이 주목받고 있다. 출혈, 여드름 등 부작용에 병원을 찾았으나 진료가 계속 미뤄지자 직접 제거에\n",
            "나선 것이다. 영국 일간 데일리메일에 따르면 영국 워릭셔에 사는 키에라 플랫\n",
            "\n",
            "  * \"하한가 치길래 '줍줍' 했는데…망한 건가요\" 초조한 개미들 [한경우의 케이스스터디]\n",
            "\n",
            "미국에서 간암 신약 승인이 불발된 HLB가 2거래일 연속으로 하한가를 기록한 뒤 눈에 띄는 반등을 보이지 못하고 있습니다. 급락한 뒤 기술적\n",
            "반등을 노리고 주식을 매수한 투자자들, 특히 개인 투자자들(개미)은 속이\n",
            "\n",
            "  * 김호중 50분 구속심사 종료…포승줄 묶인 채 유치장으로\n",
            "\n",
            "음주 운전을 하다 사고를 낸 뒤 달아난 혐의를 받는 가수 김호중(33)씨가 구속 심사를 마치고 포승줄에 묶인 채 경찰서 유치장으로 옮겨졌다.\n",
            "서울중앙지법은 낮 12시 30분부터 약 50분 동안 구속 전 피의자 심문(\n",
            "\n",
            "  * “강형욱 부부 영상 보다 열받아”… 박훈 변호사, 前 직원 무료 변호 선언한 이유\n",
            "\n",
            "영화 ‘부러진 화살’의 실제 인물로 알려진 박훈 변호사가 반려견 훈련사 강형욱 보듬컴퍼니 대표의 갑질 논란 가운데 ‘사무실 CCTV 감시\n",
            "의혹’를 두고 분노했다. “직원 감시 용도가 아니었다”는 강씨 부부의 해명에도\n",
            "\n",
            "  * \"10만원 내기 싫다\"…캐리어 바퀴 다 뜯고 탑승한 남성\n",
            "\n",
            "한 여행객이 저가 항공사의 추가 수화물 요금을 내지 않겠다며 기내 캐리어의 바퀴를 뜯어냈다. 연합뉴스가 25일(현지시간) 프랑스 일간\n",
            "르피가로를 인용한 보도를 보면, 다니엘 갈바레스는 스페인 발레아레스 제도에서 휴가\n",
            "\n",
            "  * 정치권, 시민들, 해병대 전우까지…“‘채상병 특검 거부’를 거부한다”\n",
            "\n",
            "“대통령의 특검 거부 국민이 거부한다” “채상병 특검법 통과 국민의 명령이다” 해병대 전우회원들부터, 각 시민 단체와 모임 깃발 아래 모인\n",
            "시민들, 전국 곳곳에서 온 야당 당원들까지. 서울역 출구부터 숭례문까지 5개\n",
            "\n",
            "  * '음주 뺑소니' 김호중 15일 만에 구속…경찰 수사 탄력\n",
            "\n",
            "범인도피 방조에서 교사로 혐의 변경 가능성도 음주 뺑소니와 운전자 바꿔치기 등 혐의를 받는 가수 김호중이 사건 발생 15일 만에 구속됐다.\n",
            "김 씨 신병 확보에 성공하면서 경찰은 음주 뺑소니뿐만 아니라 증거인멸 혐의\n",
            "\n",
            "  * 강형욱 사과·해명에 前 직원 반박...박훈 변호사는 무료 변론 자청\n",
            "\n",
            "반려견 훈련사인 강형욱(39) 보듬컴퍼니 대표가 직원을 감시하고 괴롭혔다는 의혹을 전면 부인한 가운데 전 직원이 강 대표의 일부 해명에 대해\n",
            "다시 반박하고 나섰다. 강 대표와 배우자인 수잔 엘더 보듬컴퍼니 이사는 각\n",
            "\n",
            "  * \"부기 빠지고 눈 커져\" …엄지원 동안 마사지, 주의할 점은?\n",
            "\n",
            "배우 엄지원이 집에서 꾸준히 따라하면 누구나 동안이 될 수 있는 '홈케어 꿀팁'을 공개했다. 23일 '엄지원 Umjeewon'에는 '배우\n",
            "엄지원의 홈 페이셜 케어 꿀팁 소개합니다'라는 제목의 영상이 게재됐다. 영상\n",
            "\n",
            "  * “아무도 이럴줄 몰랐다” 충격 받은 삼성…완전 당했다\n",
            "\n",
            "“베끼던 중국에 당했다” 충격적인 결과가 나왔다. 삼성전자가 압도적 1위를 하던 접는 스마트폰 ‘폴더블폰’ 1위자리를 중국 화웨이에게\n",
            "뺏겼다. 삼성 제품 베끼기에 급급했던 중국이 삼성을 제치고 폴더블폰 점유율 세계\n",
            "\n",
            "  * 112에 접수된 “납치됐다 살려 달라” 전화, 신고자 알고 보니…\n",
            "\n",
            "마약을 투약한 50대가 “납치됐다. 살려 달라”고 스스로 경찰에 신고했다가 검거됐다. 25일 경기북부경찰청에 따르면 지난 4월 18일 “내가\n",
            "납치됐다, 살려 달라”는 내용의 신고전화가 112에 접수됐다. 경기북부경찰\n",
            "\n",
            "  * _재생하기_ _재생시간_ 00:59\n",
            "\n",
            "\"강형욱 CCTV 해명 열 받아\" 前직원 무료 변론 선언한 변호사\n",
            "\n",
            "반려견 훈련사 강형욱 보듬컴퍼니 대표가 직장 내 괴롭힘 논란에 해명한 뒤 사무실에 대한 CCTV 촬영을 둘러싼 갑론을박이 이어지고 있다.\n",
            "전국금속노조 상근변호사를 맡기도 했던 박훈 변호사는 25일 자신의 페이스북에\n",
            "\n",
            "  * 지하철서 드러눕고 '쩍벌'…6호선 '문신남'에 누리꾼 공분\n",
            "\n",
            "지하철 6호선 열차 안에서 좌석 3개를 점용해 누운 뒤 잠을 잔 한 남성의 사진이 공개돼 누리꾼들의 공분을 사고 있다. 25일 한 온라인\n",
            "커뮤니티에는 '6호선에 잠자는 사람 사진입니다'라는 제목의 글이 올라왔다. 글\n",
            "\n",
            "  * 햄·소시지보다도 대장암 위험 키우는 ‘이것’… 딱 이만큼만 먹어야\n",
            "\n",
            "소고기 등 붉은 육류와 햄, 소시지, 베이컨 등 가공육이 대장암 발병 위험을 키운다는 것은 잘 알려졌다. 세계보건기구(WHO) 산하\n",
            "국제암연구기구(IARC)에서도 역학연구를 검토한 후 적색육과 가공육을 발암물질 2A\n",
            "\n",
            "이전 뉴스들 보기\n",
            "\n",
            "1\n",
            "\n",
            "5\n",
            "\n",
            "다음 뉴스들 보기\n",
            "\n",
            "### 구독\n",
            "\n",
            "본문 듣기를 _종료_ 하였습니다.\n",
            "\n",
            "이 기사를 _추천_ 했습니다.\n",
            "\n",
            "추천을 _취소_ 했습니다.\n",
            "\n",
            "* * *\n",
            "\n",
            "로그인 전체서비스 서비스안내 오류신고 고객센터 기사배열 책임자 : 김수향 청소년 보호 책임자 : 이정규 각 언론사가 직접 콘텐츠를\n",
            "편집합니다. ⓒ 서울경제 이 콘텐츠의 저작권은 저작권자 또는 제공처에 있으며, 이를 무단  \n",
            "이용하는 경우 저작권법 등에 따라 법적 책임을 질 수 있습니다.  NAVER\n",
            "\n",
            "맨위로\n",
            "\n",
            "예 아니오\n",
            "\n",
            "\n",
            "본문 바로가기\n",
            "\n",
            "이전 페이지\n",
            "\n",
            "#  서울경제\n",
            "\n",
            "구독\n",
            "\n",
            "**언론사를 구독하면 메인** 에서 바로 볼 수 있어요!\n",
            "\n",
            "메인 뉴스판에서 서울경제 주요뉴스를  \n",
            "볼 수 있습니다. 보러가기\n",
            "\n",
            "**서울경제** 언론사 구독 해지되었습니다.\n",
            "\n",
            "  * 주요뉴스\n",
            "  * 숏폼\n",
            "  * 정치\n",
            "  * 경제\n",
            "  * 사회\n",
            "  * 생활\n",
            "  * 세계\n",
            "  * IT\n",
            "  * 사설/칼럼\n",
            "  * 신문보기\n",
            "  * 랭킹\n",
            "\n",
            "* * *\n",
            "\n",
            "_PICK_ _안내_\n",
            "\n",
            "언론사가 주요기사로  \n",
            "선정한 기사입니다. 언론사별 바로가기 닫기\n",
            "\n",
            "## 대통령실 \"연금개혁, 쫓기듯 타결 안돼…청년세대 의견 반영해야\"\n",
            "\n",
            "_입력_ 2024.05.25. 오후 6:37\n",
            "\n",
            "기사원문\n",
            "\n",
            "_박동휘 기자_\n",
            "\n",
            "  * _박동휘 기자_\n",
            "\n",
            "구독 구독중\n",
            "\n",
            "구독자\n",
            "\n",
            "    0\n",
            "\n",
            "응원수\n",
            "\n",
            "    0\n",
            "\n",
            "더보기\n",
            "\n",
            "추천\n",
            "\n",
            "  * 쏠쏠정보 0\n",
            "  * 흥미진진 0\n",
            "  * 공감백배 0\n",
            "  * 분석탁월 0\n",
            "  * 후속강추 0\n",
            "\n",
            "댓글\n",
            "\n",
            "본문 요약봇\n",
            "\n",
            "**본문 요약봇도움말** 자동 추출 기술로 요약된 내용입니다. 요약 기술의 특성상 본문의 주요 내용이 제외될 수 있어, 전체 맥락을 이해하기\n",
            "위해서는 기사 본문 전체보기를 권장합니다. 닫기\n",
            "\n",
            "텍스트 음성 변환 서비스 사용하기\n",
            "\n",
            "_성별_ 남성 여성\n",
            "\n",
            "_말하기 속도_ 느림 보통 빠름\n",
            "\n",
            "이동 통신망을 이용하여 음성을 재생하면 별도의 데이터 통화료가 부과될 수 있습니다.\n",
            "\n",
            "본문듣기 시작\n",
            "\n",
            "닫기\n",
            "\n",
            "글자 크기 변경하기\n",
            "\n",
            "  * 가 _1단계_ 작게\n",
            "  * 가 _2단계_ 보통\n",
            "  * 가 _3단계_ 크게\n",
            "  * 가 _4단계_ 아주크게\n",
            "  * 가 _5단계_ 최대크게\n",
            "\n",
            "SNS 보내기\n",
            "\n",
            "인쇄하기\n",
            "\n",
            "_연합뉴스_  \n",
            "[서울경제]  \n",
            "  \n",
            "대통령실은 25일 이재명 더불어민주당 대표가 기자회견을 열어 국민연금 개혁안을 21대 국회에서 처리하자고 윤석열 대통령과 국민의힘에 거듭\n",
            "요구한 데 대해 시간에 쫓기듯 졸속으로 결정해서는 안 된다고 밝혔다.  \n",
            "  \n",
            "대통령실 고위 관계자는 이날 \"보험료율과 소득대체율 수치에 대한 결정 자체도 중요하지만, 국민연금은 국\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WebBaseLoader는 HTML 웹페이지의 모든 텍스트를 추출할 때 사용하는 로더임.\n",
        "\n",
        "WebBaseLoader의 경우 다양한 자식 클래스들이 있어서 이걸 쓰면 알아서 파싱을 잘 해주는 듯함."
      ],
      "metadata": {
        "id": "CXJnjq64Y7No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "# 웹 페이지 \"https://news.naver.com/\"에서 데이터를 로드하는 WebBaseLoader 객체를 생성합니다.\n",
        "loader = WebBaseLoader(\"https://news.naver.com/\")\n",
        "\n",
        "# SSL 인증서 오류 우회\n",
        "loader.requests_kwargs = {\"verify\": False}\n",
        "\n",
        "# 로더를 사용하여 데이터를 불러옵니다.\n",
        "web_data = loader.load()\n",
        "# 불러온 데이터를 출력합니다.\n",
        "display(web_data[0].page_content[2000:2500].replace(\"\\n\", \"\"))\n",
        "\n"
      ],
      "metadata": {
        "id": "GhSsd0-BL8dV",
        "outputId": "f3463781-be51-4c8f-e457-7bab20d120d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py:1100: InsecureRequestWarning: Unverified HTTPS request is being made to host 'news.naver.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'의원이 \"특검을 당당매일경제05월 26일 00:12구독강형욱 “아내는 통일교 2세…스무 살에 탈퇴했다”직원들에 대한 ‘갑질’ 논란에 휘말린 유명 반려견 훈련사 강형욱이 아내의 종교에 대해 처음으로 입을 열었다. 강형욱은 아내 수잔 엘더가 과거 통일교였다고 밝혔다. 25일 디스패치는 강형욱과 나눈 인터뷰를 공개했다. 서울경제05월 26일 00:03구독“5% 확률로 살아돌아와”…금지된 박수소리 울려퍼진 英의회 무슨 일의사당 내에서 박수치는 게 허용되지 않는 영국에서 최근 모든 의원이 기립박수를 치는 일이 있었다. 박수를 받은 주인공은 보수당 하원 의원인 크레이그 맥킨레이다. 25일(현지시간) 영국 일간 텔레그래프에 따르면 맥킨레새로보기노컷뉴스05월 26일 00:02구독이재명 \"\\'소득대체율 44%\\' 연금개혁 여당안 수용\"…與 \"언론플레이\"(종합)더불'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "찾아보니 LLM에게 전달해서 파싱을 할 수도 있나보다.\n",
        "\n",
        "한번 해보자\n",
        "\n"
      ],
      "metadata": {
        "id": "e-tDjcBMap_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import AsyncChromiumLoader\n",
        "from langchain_community.document_transformers import Html2TextTransformer\n",
        "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
        "from langchain.chains import create_extraction_chain\n",
        "\n",
        "# 크롤링할 URL 목록을 설정합니다.\n",
        "urls = [\"https://n.news.naver.com/article/011/0004345031?cds=news_media_pc\"]\n",
        "\n",
        "# AsyncChromiumLoader를 사용하여 URL에서 비동기적으로 문서를 로드합니다.\n",
        "loader = AsyncChromiumLoader(urls)\n",
        "# 로드된 문서를 가져옵니다.\n",
        "docs = loader.load()\n",
        "\n",
        "# # 변환 작업\n",
        "bs_transformer = BeautifulSoupTransformer()\n",
        "# HTML 문서를 변환합니다. p, li, div, a 태그의 내용을 추출합니다.\n",
        "docs_transformed = bs_transformer.transform_documents(\n",
        "    docs,\n",
        "    tags_to_extract=[\"div\"],\n",
        ")\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "  chunk_size=1000, chunk_overlap=0\n",
        ")\n",
        "splits = splitter.split_documents(docs_transformed)\n",
        "\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"뉴스 제목\": {\"type\": \"string\"},\n",
        "        \"언론사\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"뉴스 제목\", \"언론사\"],\n",
        "}\n",
        "\n",
        "def extract(content: str, schema: dict):\n",
        "    return create_extraction_chain(schema=schema, llm=llm).run(content)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "extracted_contents = []\n",
        "for split in tqdm(splits):\n",
        "    extracted_content = extract(content=split.page_content, schema=schema)\n",
        "    extracted_contents.extend(extracted_content)"
      ],
      "metadata": {
        "id": "4HL9zUt1axMI",
        "outputId": "71a8d88e-1365-4725-a610-ae29775a2e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/55 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "GenerativeServiceClient.generate_content() got an unexpected keyword argument 'function_call'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-2cc64145b0d3>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mextracted_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mextracted_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mextracted_contents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-2cc64145b0d3>\u001b[0m in \u001b[0;36mextract\u001b[0;34m(content, schema)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_extraction_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"`run` supports only one positional argument.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             return self(args[0], callbacks=callbacks, tags=tags, metadata=metadata)[\n\u001b[0m\u001b[1;32m    601\u001b[0m                 \u001b[0m_output_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             ]\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py\u001b[0m in \u001b[0;36mwarning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0memit_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mawarning_emitting_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m         }\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         return self.invoke(\n\u001b[0m\u001b[1;32m    384\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRunnableConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_chain_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/base.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             outputs = (\n\u001b[0;32m--> 156\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnew_arg_supported\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mrun_manager\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallbackManagerForChainRun\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     ) -> Dict[str, str]:\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_manager\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseLanguageModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             return self.llm.generate_prompt(\n\u001b[0m\u001b[1;32m    139\u001b[0m                 \u001b[0mprompts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    598\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mrun_managers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                     \u001b[0mrun_managers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_llm_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         flattened_outputs = [\n\u001b[1;32m    458\u001b[0m             \u001b[0mLLMResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[list-item]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 results.append(\n\u001b[0;32m--> 446\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    447\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    672\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, **kwargs)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m         )\n\u001b[0;32m--> 724\u001b[0;31m         response: GenerateContentResponse = _chat_with_retry(\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36mwrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    328\u001b[0m         )\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mretry_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mWrappedFn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mretry_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRetryCallState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_object\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36miter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_post_retry_check_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretry_state\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"RetryCallState\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_explicit_retry\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretry_run_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutcome\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tenacity/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoAttempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# noqa: B902\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                     \u001b[0mretry_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m             ) from e\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_google_genai/chat_models.py\u001b[0m in \u001b[0;36m_chat_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_chat_with_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Do not retry for these errors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFailedPrecondition\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: GenerativeServiceClient.generate_content() got an unexpected keyword argument 'function_call'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러 페이지 로드도 가능하다."
      ],
      "metadata": {
        "id": "qsjrzkUtZyMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹 페이지 URL 목록을 사용하여 WebBaseLoader 객체를 생성합니다.\n",
        "loader = WebBaseLoader([\"https://news.naver.com/\", \"https://news.daum.net\"])\n",
        "docs = loader.load()  # 지정된 웹 페이지에서 문서를 로드합니다.\n",
        "# 로드된 문서를 출력합니다.\n",
        "print(\"Naver\")\n",
        "print(docs[0].page_content.replace(\"\\n\", \"\")[200:1000])\n",
        "print(\"===\" * 20)\n",
        "print(\"Daum\")\n",
        "print(docs[1].page_content.replace(\"\\n\", \"\")[:1000])"
      ],
      "metadata": {
        "id": "BuvaNaxsZ13z",
        "outputId": "2deea3d5-5b3e-460a-e6d0-0b366da3c383",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naver\n",
            "                        구독설정                                경향신문05월 25일 21:58구독마지막 국회 본회의 앞두고...시민사회·야7당 “채 상병 특검법 통과시켜라”시민사회단체와 7개 야당이 오는 28일 21대 국회 마지막 본회의에서 ‘채 상병 특별검사법’의 재의결을 촉구했다. 더불어민주당, 정의당, 새로운미래, 조국혁신당, 진보당, 기본소득당, 사회민주당 등 야7당 정치인 및JIBS05월 25일 22:32구독레인지로버 내팽개치고 떠난 '중국 왕서방' 대포차 악용  우려차량을 방치하고 제주를 떠난 중국인들이 잇따르면서 대포차 양산 우려를 키우고 있습니다. 오늘(25일) 서귀포시에 따르면 서귀포시 안덕면에 살던 중국인 A 씨가 몰던 레인지로버를 비롯한 외국인 소유주 차량 15대에 최디지털타임스05월 25일 23:15구독\"300만원 줄게\"…경복궁 낙서 시킨 30대 `이팀장` 구속법원 \"증거인멸·도망 염려\" 지난해 10대 청소년들에게 경복궁 담장에 스프레이로 '영화공짜' 등의 낙서를 하도록 사주한 30대 남성이 25일 구속됐다. 이날 법조계에 따르면 서울중앙지법 남천규 영장전담 부장판사는 문오마이뉴스05월 25일 19:23구독\"이거 페미 영화예요?\" 남자만 나오는 '매드맥스' 신작의 실체* 이 글에는 영화의 스포일러가 포함돼 있습니다. ▲ <퓨리오사: 매드맥스 사가> 메인 포스터 ⓒ 워너브러더스 코리아 \"<매드맥스>가 왜 페미임? 마초 영화 그 자체인데.\" 새로운 영화가 개봉할 때마다 팬들끼리 '페SBS Biz05월 25일 20:58구독\"사장님, 여기 소주 한 잔\n",
            "============================================================\n",
            "Daum\n",
            "홈 | 다음뉴스본문 바로가기메뉴 바로가기뉴스관련 서비스연예스포츠 뉴스 메인메뉴홈사회정치경제국제문화IT연재포토팩트체크홈이슈 기사 목록국제                                    바이든 \"한미일 3각 협력, 누구도 상상 못 한 일\"                                문화                                    [날씨] 전국에 비‥수도권 최대 60mm                                국제                                    파리올림픽 교통통제에 자전거 배달업 특수                                IT                                    보잉 우주선 스타라이너, 유인 비행 성공할까[우주이야기]                                국제                                    尹에 \"말참견 말라\" 발언한 中외교부 입 왕원빈 사임                                국제                                    '하마스 억류' 인질 석방 협상 재개…이번 주 이집트·카타르 중재                                문화                                    아이스크림 먹고 '찌릿'… 치료 받아야 할까?                                정치                                    `촛불` 붙든 北매체들 \"친미굴종 尹과 여편네 김건희…이승만처럼 타도\"                                정치                                    대통령실∙국힘, 이재명 대표 제안 거부…“연금개혁안, 22대 국회에서”                                정치                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여러 URL을 동시에 로드도 되고, requests_per_second를 조정해서 제한할수도 있다."
      ],
      "metadata": {
        "id": "Iy17zFgFZ7HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 웹 페이지 URL 목록을 사용하여 WebBaseLoader 객체를 생성합니다.\n",
        "loader = WebBaseLoader([\"https://news.naver.com/\", \"https://news.daum.net\"])\n",
        "loader.requests_per_second = 1  # 초당 요청 수를 1로 설정합니다.\n",
        "docs = loader.aload()  # 지정된 웹 페이지에서 문서를 로드합니다.\n",
        "# 로드된 문서를 출력합니다.\n",
        "print(\"Naver\")\n",
        "print(docs[0].page_content.replace(\"\\n\", \"\")[200:1000])\n",
        "print(\"===\" * 20)\n",
        "print(\"Daum\")\n",
        "print(docs[1].page_content.replace(\"\\n\", \"\")[:1000])"
      ],
      "metadata": {
        "id": "IrMMCxRWaEta",
        "outputId": "793dc9a9-1448-4d53-d3db-b12781cb6b62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching pages: 100%|##########| 2/2 [00:01<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naver\n",
            "                        구독설정                                kbc광주방송05월 25일 23:14구독한 달간 맥도날드만 먹었더니..'슈퍼사이즈 미' 스펄록 감독 별세패스트푸드의 폐해를 낱낱이 고발한 다큐멘터리 영화 '슈퍼 사이즈 미'(Super Size Me)의 감독 모건 스펄록이 암 투병 끝에 향년 53세로 별세했다고 AP통신이 24일(현지시각) 보도했습니다. 지난 2004년JTBC05월 25일 23:32구독동영상재생시간04:34[단독] '상사 욕설' 녹음했다가 고소당한 공공기관 직원…법정에선 '기립박수' 쏟아졌다해양수산부 산하의 한 공공기관에서 직장 내 괴롭힘을 호소하는 동료를 위해 신고에 나섰던 연구원이 오히려 고소·고발을 당했습니다. 법정에 피고인으로 서야 했는데요. 그 재판 결과가 어땠을지, 부글터뷰 이상엽 기자의 단이코노미스트05월 26일 00:18구독9년 전 ‘다이소 화장품’에 혹평했던 유튜버, 지금은?[허태윤의 브랜드 스토리]다이소의 진화는 경이롭다. 생활용품을 중심으로 ‘1000원 경영’을 해온 다이소가 영역을 전방위로 넓히고 있다. 특히 뷰티 시장에서의 진화는 이 분야 독주체제를 구가하고 있던 ‘CJ올리브 영’을 긴장하게 하고 있다.MBN05월 26일 00:08구독10대에 경복궁 낙서 지시 '이 팀장' 구속…\"증거인멸·도망 우려\"10대 학생들에게 경복궁 담벼락 낙서를 지시한 '이 팀장' 강 모 씨가 오늘(25일) 구속됐습니다. 서울중앙지법은 문화재보호법상 손상 또는 은닉 및 저작권법 위반 등 혐의를 받는 강 씨에 대해 증거인멸 및 도주 우려세계일\n",
            "============================================================\n",
            "Daum\n",
            "홈 | 다음뉴스본문 바로가기메뉴 바로가기뉴스관련 서비스연예스포츠 뉴스 메인메뉴홈사회정치경제국제문화IT연재포토팩트체크홈이슈 기사 목록국제                                    바이든 \"한미일 3각 협력, 누구도 상상 못 한 일\"                                문화                                    [날씨] 전국에 비‥수도권 최대 60mm                                국제                                    파리올림픽 교통통제에 자전거 배달업 특수                                IT                                    보잉 우주선 스타라이너, 유인 비행 성공할까[우주이야기]                                국제                                    尹에 \"말참견 말라\" 발언한 中외교부 입 왕원빈 사임                                국제                                    '하마스 억류' 인질 석방 협상 재개…이번 주 이집트·카타르 중재                                문화                                    아이스크림 먹고 '찌릿'… 치료 받아야 할까?                                정치                                    `촛불` 붙든 北매체들 \"친미굴종 尹과 여편네 김건희…이승만처럼 타도\"                                정치                                    대통령실∙국힘, 이재명 대표 제안 거부…“연금개혁안, 22대 국회에서”                                정치                       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 04. 판다스 데이터프레임\n",
        "\n",
        "이건 csv를 가져다가 쓸 때 좋아보임.\n",
        "\n",
        "https://wikidocs.net/233823\n",
        "\n",
        "를 그냥 참고할 것.\n"
      ],
      "metadata": {
        "id": "ghJBGMGsaQbq"
      }
    }
  ]
}