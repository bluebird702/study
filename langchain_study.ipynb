{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJro/uP3MCu4KAm4GhWXGV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluebird702/study/blob/main/langchain_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYaGRdqvdguf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 문서는 langchain study를 하면서 정리한 노트입니다."
      ],
      "metadata": {
        "id": "xtL86y2zesDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습 준비\n",
        "colab에서 예제를 실행할 것이므로 Google AI Studio에 계정을 등록하고 Key를 얻는다. 자세한 내용은 다음 문서를 참고한다.\n",
        "\n",
        "[Gemini Key 발급받아오기](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb#scrollTo=gHYFrFPjSGNq)\n",
        "\n",
        "# 환경 테스트\n",
        "다음과 같이 테스트해보자. 공식 문서에 있는 내용을 그대로 테스트해본다.\n",
        "\n",
        "[문서 링크](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb#scrollTo=FFPBKLapSCkM)\n",
        "\n"
      ],
      "metadata": {
        "id": "ftQ7pupUexag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google python sdk 설치\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "8hcrFi8yfxwF",
        "outputId": "ad05b2f7-22ac-4b53-84a1-71cb01ca9917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/142.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/142.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/663.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.6/663.6 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 왼쪽의 열쇠 버튼에 GOOGLE_API_KEY를 등록한다음에 다음 코드를 돌려서 라이브러리를 초기화\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    display(m.name) # colab에서는 print 말고 display를 써야 wrapping된 결과를 얻을 수 있다.\n"
      ],
      "metadata": {
        "id": "aDExK8Xshlq1",
        "outputId": "7463257c-7ac1-4b75-fc7a-a8f8977aa85f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-vision-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-pro-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-pro-vision'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음의 코드를 테스트해보자\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "zNvUFwMlgQ68"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gemini-pro를 일단 사용해본다.\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "QhZvCoMEiynJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time은 맨 첫줄에서만 동작함. 그래서 코드셀을 나눴음.\n",
        "%%time\n",
        "response = model.generate_content(\"삶의 의미가 멀까?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "4XjywuaJivBM",
        "outputId": "ff7b88bb-ce3e-4568-91a4-9b3fcc75921a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 108 ms, sys: 9.95 ms, total: 118 ms\n",
            "Wall time: 8.15 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> 삶의 의미는 개인과 문화에 따라 다르게 해석되는 개념이므로 멀거나 가까울 수 없습니다.\n> \n> 어떤 사람들은 삶의 의미가 목표, 성취, 개인적 성장에 있다고 믿습니다. 다른 사람들은 관계, 가족, 커뮤니티에 의미를 부여합니다. 또 다른 사람들은 종교, 영성, 더 큰 목적에서 의미를 찾습니다.\n> \n> 다음은 사람들이 삶의 의미를 찾는 데 도움이 되는 몇 가지 일반적인 경로입니다.\n> \n> * **목적 또는 열정 찾기:** 사람들은 열정을 추구하고, 특정 목표를 향해 노력하고, 그들의 삶에 목적 의식을 줄 수 있는 활동에 참여함으로써 의미를 찾을 수 있습니다.\n> * **관계 구축:** 강한 대인 관계, 사랑하는 사람, 지지적인 커뮤니티는 인생에 의미와 목적을 줄 수 있습니다.\n> * **공헌하기:** 자원봉사, 멘토링, 사회적 원인 지원과 같은 활동은 개인이 사회에 긍정적인 기여를 하며 의미를 찾는 데 도움이 될 수 있습니다.\n> * **성장 및 학습:** 지속적인 성장과 학습에 투자하면 사람들은 삶의 복잡성에 적응하고 목적 의식을 유지하도록 도울 수 있습니다.\n> * **영성 또는 종교 탐구:** 일부 사람들은 영성, 종교 또는 더 큰 목적에 대한 믿음을 통해 삶의 의미를 찾습니다.\n> \n> 결국 삶의 의미는 개인이 자신만의 경험, 가치관, 믿음을 기반으로 결정하는 주관적인 것입니다. 멀거나 가까운 것은 아니며 지속적으로 진화하고 변화하는 과정입니다."
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream으로 노출하려면 출력을 다르게 해야한다.\n",
        "%%time\n",
        "response = model.generate_content(\"삶의 의미가 멀까?\", stream=True)\n",
        "for chunk in response:\n",
        "  display(chunk.text)\n",
        "  display(\"_\"*80)"
      ],
      "metadata": {
        "id": "CT6h9ihXjkh8",
        "outputId": "7d5b834d-d8fc-42d7-d045-660e43f9a1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'삶의 의미에 대한 답은 복잡하고 개인적이며 철'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'학자와 사상가 사이에 수세기 동안 논쟁의 여지가 있는 주제였습니다. 삶의 의미에 대한 몇'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' 가지 일반적인 견해는 다음과 같습니다.\\n\\n**객관적 의미론:**\\n* 삶에는 모든 사람에게 적용되는 객관적이고 고유한 의미가 있습니다. 이 의미는 종교적 신념, 도덕 원리, 과학적 발견을 포함'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'한 외부 출처에서 찾을 수 있습니다.\\n\\n**주관적 의미론:**\\n* 삶의 의미는 개인이 창조하고 주관적입니다. 각 개인은 자신의 경험, 가치관, 목표를 기반으로 자신의 의미를 결정합니다.\\n\\n**무의미론:**\\n* 삶에는 내재적이거나 고유한 의미가 없습니다. 존재 자체는 무의미하며, 의미는 개인이 부여합니다.\\n\\n**목적론적 의미론:**\\n* 삶에는 특정 목표나 목적이 있습니다'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'. 이 목적은 개인적인 성장, 사회적 기여, 환경 보호 등 다양할 수 있습니다.\\n\\n**실존주의적 의미론:**\\n* 삶에 본질적인 의미는 없습니다. 개인은 자신의 의미를 찾고 창조해야 합니다. 이는 자유와 책임, 정통성을 강조합니다.\\n\\n**진화적 의미론:**\\n* 삶의 의미는 진화적 과정에서 발견됩니다. 인간의 목적은 생존, 번식, 진화적 성공을 촉진하는 행동을 하는 것입니다.\\n\\n**불교적 의미론:**\\n* 삶은 고통과 무상의 순환입니다. 삶의 의미는 이 순환에서 벗어나 깨달음을 얻는 것입니다.\\n\\n**삶의 의미 찾기:**\\n\\n삶의 의미를 찾는 것은 복잡한 여정입니다. 다음 팁이 도움이 될 수 있습니다.\\n\\n* **자기 성찰:** 자신의 가치관, 목표, 열정을 탐구하세요.\\n* **다른 관점 탐구:** 다른 문화, 철학, 종교를 연구하여 다양'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'한 의미의 관점에 대해 배우세요.\\n* **경험하기:** 새로운 것을 시도하고, 다른 사람들과 교류하고, 세계를 탐구함으로써 다양한 의미의 잠재성을 발견하세요.\\n* **목적 추구:** 당신을 충족시키고 목적 의식을 주는 활동이나 목표에 참여하세요.\\n* **의미 부여:** 자신의 경험과 행동에 의도적으로 의미를 부여하세요.\\n\\n궁극적으로 삶의 의미는 개인이 결정하는 것입니다. 옳고 그른 대답은 없으며, 모든 사람은 자신의 의미를 찾아야 합니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 182 ms, sys: 23.7 ms, total: 206 ms\n",
            "Wall time: 11.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "요정도에서 gemini설정을 마치고 langchain 학습으로 넘어간다.\n",
        "\n",
        "langchain학습은 [테디노트님의 ebook](https://wikidocs.net/book/14314)으로 진행해본다."
      ],
      "metadata": {
        "id": "4iLIZOaWkNEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch01 LangChain 시작하기 노트\n",
        "1장은 설정을 하고 있는데, openai로 예제가 나와 있다.\n",
        "\n",
        "colab에서 테스트를 쉽게 하고 싶으니 gemini로 바꿔서 테스트해보자.\n",
        "\n",
        "일단 langchain library를 설치한다."
      ],
      "metadata": {
        "id": "gBJVwwISk-7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain 업데이트\n",
        "!pip install -U langchain langchain-community langchain-experimental langchain-core langchain-google-genai langsmith"
      ],
      "metadata": {
        "id": "Wdfxp_jblClX",
        "outputId": "84be7802-a34f-4c35-ee21-02a6832ec361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.15-py3-none-any.whl (814 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m814.5/814.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-community\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-experimental\n",
            "  Downloading langchain_experimental-0.0.57-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.1.41-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-1.0.1-py3-none-any.whl (28 kB)\n",
            "Collecting langsmith\n",
            "  Downloading langsmith-0.1.45-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.2/104.2 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-generativeai<0.5.0,>=0.4.1 (from langchain-google-genai)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith)\n",
            "  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting google-ai-generativelanguage==0.4.0 (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.4.0-py3-none-any.whl (598 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m598.7/598.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.27.0)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (2.11.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (3.20.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.10.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.4.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.23.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (4.9)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.63.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.62.1)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (1.48.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.5.0,>=0.4.1->langchain-google-genai) (0.6.0)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, google-ai-generativelanguage, langchain, google-generativeai, langchain-google-genai, langchain-experimental\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.1\n",
            "    Uninstalling google-ai-generativelanguage-0.6.1:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.1\n",
            "  Attempting uninstall: google-generativeai\n",
            "    Found existing installation: google-generativeai 0.5.0\n",
            "    Uninstalling google-generativeai-0.5.0:\n",
            "      Successfully uninstalled google-generativeai-0.5.0\n",
            "Successfully installed dataclasses-json-0.6.4 google-ai-generativelanguage-0.4.0 google-generativeai-0.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.15 langchain-community-0.0.32 langchain-core-0.1.41 langchain-experimental-0.0.57 langchain-google-genai-1.0.1 langchain-text-splitters-0.0.1 langsmith-0.1.45 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.0 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "c52def5a41c5479482585134f2086a62"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 잘되는 지 기본 예제 코드를 수행해본다."
      ],
      "metadata": {
        "id": "C84zlChmkovo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# 객체 생성\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "# 물어보자.\n",
        "result = llm.invoke(\"넌 누구냐!\")\n",
        "display(f\"[답변]: {result.content}\")"
      ],
      "metadata": {
        "id": "wJ92-378k1p0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "프롬프트 템플릿도 한번 써보자.\n",
        "\n",
        "일단 prompt를 만든다."
      ],
      "metadata": {
        "id": "q-t4c2Pim6GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"{country}의 수도는 뭐야?\"\n",
        "\n",
        "# 템플릿 완성\n",
        "prompt = PromptTemplate.from_template(template=template)\n",
        "prompt"
      ],
      "metadata": {
        "id": "YZJEwueRne3k",
        "outputId": "a0b2f8f2-11e2-4c42-832a-fdad64159d77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], template='{country}의 수도는 뭐야?')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 다음에 prompt를 써서 요청을 날려보자"
      ],
      "metadata": {
        "id": "5YuxfaoIoXSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm) # 위에서 prompt와 llm을 만드는 코드를 실행한 후에 여기를 돌려야 한다.\n",
        "\n",
        "llm_chain.invoke({\"country\": \"대한민국\"}) # 요거는 서울"
      ],
      "metadata": {
        "id": "dpltUWLcn2aa",
        "outputId": "be19832a-dcc4-426b-a172-ff9a727dc1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '대한민국', 'text': '서울'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "apply()로 여러개의 입력도 한번에 처리가 가능하다."
      ],
      "metadata": {
        "id": "rLpu5fQpoZQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\":\"네덜란드\"}]\n",
        "\n",
        "result = llm_chain.apply(input_list)\n",
        "\n",
        "display(result)\n",
        "\n",
        "for res in result:\n",
        "  display(res[\"text\"].strip())"
      ],
      "metadata": {
        "id": "y8PLy6Qfod1T",
        "outputId": "a406948b-ff47-4217-efab-8b4eb39b241a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'text': '캔버라'}, {'text': '베이징'}, {'text': '암스테르담'}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'캔버라'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'베이징'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'암스테르담'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate()로 좀 더 자세한 추가정보를 출력할 수 있다."
      ],
      "metadata": {
        "id": "h0sF1Uweo-4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\":\"네덜란드\"}]\n",
        "\n",
        "result = llm_chain.generate(input_list)\n",
        "\n",
        "display(result)"
      ],
      "metadata": {
        "id": "ciVXZxkcpGJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰 사용량을 바로 보려면 다음과 같이 찍으면 된다고 하는데 OpenAI는 되나본데, Gemini는 아무것도 안나온다. 따로 방법을 찾아보자."
      ],
      "metadata": {
        "id": "khmIifyLqs3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.llm_output"
      ],
      "metadata": {
        "id": "Y1XNDFOrqxm1",
        "outputId": "234fe11e-e872-441d-dfbc-59848d242758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2개 이상의 변수를 템플릿 안에 정의하는 것도 가능하다."
      ],
      "metadata": {
        "id": "6tOXnzbNrQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"{area1}와 {area2}의 시차는 몇시간이야?\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "id": "7UKfHPH3rVxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "KIdklYmOrh4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(llm_chain.invoke({\"area1\": \"서울\", \"area2\": \"파리\"}))"
      ],
      "metadata": {
        "id": "zRa_8MiKrmeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [\n",
        "    {\"area1\": \"파리\", \"area2\": \"뉴욕\"},\n",
        "    {\"area1\": \"서울\", \"area2\": \"하와이\"},\n",
        "    {\"area1\": \"켄버라\", \"area2\": \"베이징\"},\n",
        "]\n",
        "\n",
        "# 반복문으로 결과 출력\n",
        "result = llm_chain.apply(input_list)\n",
        "for res in result:\n",
        "    display(res[\"text\"].strip())"
      ],
      "metadata": {
        "id": "AUlKGqUprsfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stream으로 출력도 가능하다만 OpenAI로 좀 다른거 같다. stream이란 함수를 호출해서 출력한다."
      ],
      "metadata": {
        "id": "fhMdyVyMsoNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0, #창의성\n",
        "    max_output_tokens=2048,\n",
        ")\n",
        "\n",
        "question = \"대한민국에 대해서 300자 내외로 최대한 상세히 알려줘\"\n",
        "\n",
        "for chunk in llm.stream(question):\n",
        "    display(to_markdown(chunk.content))\n",
        "    display(to_markdown(\"---\"))"
      ],
      "metadata": {
        "id": "4sR3ixAksq-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain 생성에서 LCEL(LangChain Expression Language)도 가능한지 살펴본다."
      ],
      "metadata": {
        "id": "YSQtF6uiuBB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 주어진 나라에 대하여 수도를 묻는 프롬프트 템플릿을 생성합니다.\n",
        "template = \"\"\"\n",
        "당신은 친절하게 답변해 주는 친절 봇입니다. 사용자의 질문에 [FORMAT]에 맞추어 답변해 주세요.\n",
        "답변은 항상 한글로 작성해 주세요.\n",
        "\n",
        "질문:\n",
        "{question}에 대하여 설명해 주세요.\n",
        "\n",
        "FORMAT:\n",
        "- 개요:\n",
        "- 예시:\n",
        "- 출처:\n",
        "\"\"\"\n",
        "\n",
        "template = \"\"\"\n",
        "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
        "\n",
        "상황:\n",
        "{question}\n",
        "\n",
        "FORMAT:\n",
        "- 영어 회화:\n",
        "- 한글 해석:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# OpenAI 챗모델을 초기화합니다.\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0, #창의성\n",
        "    max_output_tokens=2048,\n",
        ")\n",
        "\n",
        "# 문자열 출력 파서를 초기화합니다.\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "# 완성된 Chain 을 이용하여 country 를 '대한민국'으로 설정하여 실행합니다.\n",
        "# chain.invoke({\"country\": \"대한민국\"})\n",
        "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
      ],
      "metadata": {
        "id": "NqSS-6PhuUin",
        "outputId": "41594315-264f-454c-a99d-bffceefed274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_core'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-7712ac2a9f93>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_parsers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStrOutputParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 주어진 나라에 대하여 수도를 묻는 프롬프트 템플릿을 생성합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m template = \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0m당신은\u001b[0m \u001b[0m친절하게\u001b[0m \u001b[0m답변해\u001b[0m \u001b[0m주는\u001b[0m \u001b[0m친절\u001b[0m \u001b[0m봇입니다\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m사용자의\u001b[0m \u001b[0m질문에\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mFORMAT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0m에\u001b[0m \u001b[0m맞추어\u001b[0m \u001b[0m답변해\u001b[0m \u001b[0m주세요\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_core'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"question\": \"미국에서 피자 주문\"}))"
      ],
      "metadata": {
        "id": "nTiI7hbmvl5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ebook에 있는 다른 예제도 실행해본다."
      ],
      "metadata": {
        "id": "fz-4MOAHv66A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
        "\n",
        "# input 딕셔너리에 주제를 'ice cream'으로 설정합니다.\n",
        "input = {\"topic\": \"양자역학\"}\n",
        "\n",
        "# prompt 객체의 invoke 메서드를 사용하여 input을 전달하고 대화형 프롬프트 값을 생성합니다.\n",
        "prompt.invoke(input)\n",
        "\n",
        "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
        "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
        "(prompt | model).invoke(input)"
      ],
      "metadata": {
        "id": "FuE8r61Hv9uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parse_output 메서드를 사용하여 AI 모델이 생성한 메시지 문자열로 출력합니다.\n",
        "display((prompt | model | output_parser).invoke(input))"
      ],
      "metadata": {
        "id": "KBkljGX_wIvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL 인터페이스에 있는 다른 내용은 필요할 때 보면 될 것 같고, 병렬성 예제를 돌려본다."
      ],
      "metadata": {
        "id": "EDuG92JIwqy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# {country} 의 수도를 물어보는 체인을 생성합니다.\n",
        "chain1 = ChatPromptTemplate.from_template(\"{country} 의 수도는 어디야?\") | model\n",
        "\n",
        "# {country} 의 면적을 물어보는 체인을 생성합니다.\n",
        "chain2 = ChatPromptTemplate.from_template(\"{country} 의 면적은 얼마야?\") | model\n",
        "# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\n",
        "combined = RunnableParallel(capital=chain1, area=chain2)"
      ],
      "metadata": {
        "id": "gmhhArJ6w1No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.invoke(\n",
        "    {\"country\": \"대한민국\"}\n",
        ")"
      ],
      "metadata": {
        "id": "nqfeWAwVxESf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain2.invoke({\"country\": \"미국\"})"
      ],
      "metadata": {
        "id": "urii-7RHxLed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 'country'에 대해 'combined' 객체의 'invoke' 메서드를 호출합니다.\n",
        "combined.invoke({\"country\": \"대한민국\"})"
      ],
      "metadata": {
        "id": "N5080IAqxQMy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}