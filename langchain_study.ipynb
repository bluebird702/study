{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJro/uP3MCu4KAm4GhWXGV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bluebird702/study/blob/main/langchain_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYaGRdqvdguf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 문서는 langchain study를 하면서 정리한 노트입니다."
      ],
      "metadata": {
        "id": "xtL86y2zesDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 실습 준비\n",
        "colab에서 예제를 실행할 것이므로 Google AI Studio에 계정을 등록하고 Key를 얻는다. 자세한 내용은 다음 문서를 참고한다.\n",
        "\n",
        "[Gemini Key 발급받아오기](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb#scrollTo=gHYFrFPjSGNq)\n",
        "\n",
        "# 환경 테스트\n",
        "다음과 같이 테스트해보자. 공식 문서에 있는 내용을 그대로 테스트해본다.\n",
        "\n",
        "[문서 링크](https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/python_quickstart.ipynb#scrollTo=FFPBKLapSCkM)\n",
        "\n"
      ],
      "metadata": {
        "id": "ftQ7pupUexag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# google python sdk 설치\n",
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "8hcrFi8yfxwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 왼쪽의 열쇠 버튼에 GOOGLE_API_KEY를 등록한다음에 다음 코드를 돌려서 라이브러리를 초기화\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "    display(m.name) # colab에서는 print 말고 display를 써야 wrapping된 결과를 얻을 수 있다.\n"
      ],
      "metadata": {
        "id": "aDExK8Xshlq1",
        "outputId": "9315278d-db44-4f34-f82a-adcf5de0b0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-001'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.0-pro-vision-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-1.5-pro-latest'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-pro'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'models/gemini-pro-vision'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음의 코드를 테스트해보자\n",
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "zNvUFwMlgQ68"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gemini-pro를 일단 사용해본다.\n",
        "model = genai.GenerativeModel('gemini-pro')"
      ],
      "metadata": {
        "id": "QhZvCoMEiynJ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %%time은 맨 첫줄에서만 동작함. 그래서 코드셀을 나눴음.\n",
        "%%time\n",
        "response = model.generate_content(\"삶의 의미가 멀까?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "id": "4XjywuaJivBM",
        "outputId": "f1e693cd-c245-4042-bf0f-372dae6f425f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 126 ms, sys: 13.6 ms, total: 140 ms\n",
            "Wall time: 8.65 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> 삶의 의미는 주관적이며 개인의 신념, 가치관, 경험에 따라 달라집니다. 어떤 사람들에게는 삶의 의미는 명확하고 쉽게 이해할 수 있는 반면, 다른 사람들에게는 삶의 의미는 모호하거나 계속해서 변할 수 있습니다.\n> \n> 일반적으로 받아들여지는 삶의 의미에 대한 몇 가지 견해는 다음과 같습니다.\n> \n> * **목적론:** 삶에는 미리 정해진 목적이 있으며, 우리의 목표는 그 목적을 찾아 성취하는 것입니다.\n> * **실존주의:** 삶에는 본질적으로 목적이 없으며, 우리는 자신의 의미와 목적을 창조해야 합니다.\n> * **실용주의:** 삶의 의미는 우리의 행동과 그 행동이 가져오는 결과를 통해 결정됩니다.\n> * **인본주의:** 삶의 의미는 인간의 성장, 발전, 자기실현을 통해 찾아집니다.\n> \n> 다음은 삶의 의미를 찾는 데 도움이 될 수 있는 몇 가지 추가 고려 사항입니다.\n> \n> * **자기 성찰:** 자신의 가치관, 열정, 우선순위를 탐구해 보세요.\n> * **경험 축적:** 새로운 것을 배우고, 새로운 사람을 만나고, 다양한 경험을 하세요.\n> * **의미 있는 관계 구축:** 사랑하는 사람, 친구, 커뮤니티와 연결하세요.\n> * **기여하기:** 남을 돕거나 세상을 더 나은 곳으로 만들기 위한 방법을 찾으세요.\n> * **현재 순간에 집중하기:** 과거에 연연해 하거나 미래에 대해 걱정하지 마세요. 현재 순간에 감사하세요.\n> \n> 궁극적으로 삶의 의미는 각 개인이 스스로 결정해야 하는 개인적인 여정입니다. 명확한 답이 없을 수도 있지만, 의미를 찾는 과정 자체가 인생을 보람차게 만들 수 있습니다."
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stream으로 노출하려면 출력을 다르게 해야한다.\n",
        "%%time\n",
        "response = model.generate_content(\"삶의 의미가 멀까?\", stream=True)\n",
        "for chunk in response:\n",
        "  display(chunk.text)\n",
        "  display(\"_\"*80)"
      ],
      "metadata": {
        "id": "CT6h9ihXjkh8",
        "outputId": "5e59c5a3-9663-420d-aab9-d59350c763e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 602
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'삶의 의미에 대한 질문은 길고 복잡한 역사를'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' 가진 철학적 문제입니다. 삶의 의미에 대한 단 하나의 \"진정한\" 답변은 없으며, 이에 대한'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "' 다양한 관점이 있습니다.\\n\\n**객관적인 의미론**\\n\\n* 삶의 의미는 외부 세계에 존재하고 개인의 선택이나 행동과 무관합니다.\\n* 의미는 종교적 신념, 자연 법칙 또는 다른 외부 소스에 의'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'해 결정됩니다.\\n\\n**주관적인 의미론**\\n\\n* 삶의 의미는 개인이 개별적으로 선택하거나 창조합니다.\\n* 의미는 목표, 가치관, 믿음 및 개인의 선택에 따라 달라집니다.\\n\\n**존재주의적 관점**\\n\\n* 삶의 의미는 본질적으로 없습니다.\\n* 의미는 진지하게 살면서 자신의 행동에 대한 책임을 지는 행위에 있습니다.\\n\\n**목적론적 관점**\\n\\n* 삶에는 특정 목적이나 목적이 있습니다'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'.\\n* 이 목적은 개개인마다 다르며, 그것을 찾는 것은 의미 있는 삶의 필수적인 부분입니다.\\n\\n**прагмати즘적 관점**\\n\\n* 삶의 의미는 실용적인 결과와 관련이 있습니다.\\n* 의미 있는 삶은 만족스러운 삶, 성공적인 삶 또는 사회에 기여하는 삶을 의미합니다.\\n\\n**데스티니적 관점**\\n\\n* 우리의 삶은 운명에 의해 결정되며, 우리는 자신의 삶에 의미를 선택할 수 없습니다.\\n* 의미는 운명이나 사건을 받아들이는 행위에 있습니다.\\n\\n**삶의 의미를 찾는 방법에 대한 몇 가지 추가 아이디어:**\\n\\n* **자기 반성:** 자신의 가치관, 목표, 열정을 탐구하세요. 무엇이 당신을 행복하고 충족시킵니까?\\n* **다른 사람과 연결:** 가족, 친구, 커뮤니티와의 관계에 투자하세요.\\n* **열정 추구:** 당신을 자극하고 의미를 부여하는 활동에 참여하세요.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'\\n* **도전에 맞추기:** 삶의 어려움을 기회로 받아들이고 그 과정에서 성장하세요.\\n* **현재 순간에 살기:** 과거에 머무르거나 미래에 대해 걱정하는 것보다 현재 순간을 소중히 여기세요.\\n\\n궁극적으로 삶의 의미는 각 개인이 스스로 정의해야 하는 개인적인 여정입니다. \"진정한\" 답이 없지만, 의미 있는 목적 의식을 발견하고 자신의 삶에 의미를 부여하기 위한 다양한 경로가 있습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'________________________________________________________________________________'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 205 ms, sys: 11.8 ms, total: 217 ms\n",
            "Wall time: 11.2 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "요정도에서 gemini설정을 마치고 langchain 학습으로 넘어간다.\n",
        "\n",
        "langchain학습은 [테디노트님의 ebook](https://wikidocs.net/book/14314)으로 진행해본다."
      ],
      "metadata": {
        "id": "4iLIZOaWkNEa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ch01 LangChain 시작하기 노트\n",
        "1장은 설정을 하고 있는데, openai로 예제가 나와 있다.\n",
        "\n",
        "colab에서 테스트를 쉽게 하고 싶으니 gemini로 바꿔서 테스트해보자.\n",
        "\n",
        "일단 langchain library를 설치한다."
      ],
      "metadata": {
        "id": "gBJVwwISk-7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LangChain 업데이트\n",
        "!pip install -U langchain langchain-community langchain-experimental langchain-core langchain-google-genai langsmith"
      ],
      "metadata": {
        "id": "Wdfxp_jblClX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 잘되는 지 기본 예제 코드를 수행해본다."
      ],
      "metadata": {
        "id": "C84zlChmkovo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# 객체 생성\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY\n",
        ")\n",
        "\n",
        "# 물어보자.\n",
        "result = llm.invoke(\"넌 누구냐!\")\n",
        "display(f\"[답변]: {result.content}\")"
      ],
      "metadata": {
        "id": "wJ92-378k1p0",
        "outputId": "17600140-9db0-4a40-f170-7bd640aaf365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'[답변]: 저는 Gemini, Google에서 개발한 대규모 다국어 모델입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "프롬프트 템플릿도 한번 써보자.\n",
        "\n",
        "일단 prompt를 만든다."
      ],
      "metadata": {
        "id": "q-t4c2Pim6GO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "template = \"{country}의 수도는 뭐야?\"\n",
        "\n",
        "# 템플릿 완성\n",
        "prompt = PromptTemplate.from_template(template=template)\n",
        "prompt"
      ],
      "metadata": {
        "id": "YZJEwueRne3k",
        "outputId": "a0b2f8f2-11e2-4c42-832a-fdad64159d77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['country'], template='{country}의 수도는 뭐야?')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "그 다음에 prompt를 써서 요청을 날려보자"
      ],
      "metadata": {
        "id": "5YuxfaoIoXSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm) # 위에서 prompt와 llm을 만드는 코드를 실행한 후에 여기를 돌려야 한다.\n",
        "\n",
        "llm_chain.invoke({\"country\": \"대한민국\"}) # 요거는 서울"
      ],
      "metadata": {
        "id": "dpltUWLcn2aa",
        "outputId": "be19832a-dcc4-426b-a172-ff9a727dc1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'country': '대한민국', 'text': '서울'}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "apply()로 여러개의 입력도 한번에 처리가 가능하다."
      ],
      "metadata": {
        "id": "rLpu5fQpoZQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\":\"네덜란드\"}]\n",
        "\n",
        "result = llm_chain.apply(input_list)\n",
        "\n",
        "display(result)\n",
        "\n",
        "for res in result:\n",
        "  display(res[\"text\"].strip())"
      ],
      "metadata": {
        "id": "y8PLy6Qfod1T",
        "outputId": "a406948b-ff47-4217-efab-8b4eb39b241a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "[{'text': '캔버라'}, {'text': '베이징'}, {'text': '암스테르담'}]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'캔버라'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'베이징'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'암스테르담'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate()로 좀 더 자세한 추가정보를 출력할 수 있다."
      ],
      "metadata": {
        "id": "h0sF1Uweo-4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [{\"country\": \"호주\"}, {\"country\": \"중국\"}, {\"country\":\"네덜란드\"}]\n",
        "\n",
        "result = llm_chain.generate(input_list)\n",
        "\n",
        "display(result)"
      ],
      "metadata": {
        "id": "ciVXZxkcpGJO",
        "outputId": "c9ecf4ba-dc37-42e7-9810-381dfd560490",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LLMResult(generations=[[ChatGeneration(text='캔버라', generation_info={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, message=AIMessage(content='캔버라', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-65143bf6-4a63-43e6-bb25-c610767e6d9f-0'))], [ChatGeneration(text='베이징', generation_info={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, message=AIMessage(content='베이징', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-d472131e-2bdb-4995-bb7e-7090c7735b4b-0'))], [ChatGeneration(text='암스테르담', generation_info={'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, message=AIMessage(content='암스테르담', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-77ff5e10-e8c9-44f2-ba25-0de75be62c23-0'))]], llm_output={}, run=[RunInfo(run_id=UUID('65143bf6-4a63-43e6-bb25-c610767e6d9f')), RunInfo(run_id=UUID('d472131e-2bdb-4995-bb7e-7090c7735b4b')), RunInfo(run_id=UUID('77ff5e10-e8c9-44f2-ba25-0de75be62c23'))])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "토큰 사용량을 바로 보려면 다음과 같이 찍으면 된다고 하는데 OpenAI는 되나본데, Gemini는 아무것도 안나온다. 따로 방법을 찾아보자."
      ],
      "metadata": {
        "id": "khmIifyLqs3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result.llm_output"
      ],
      "metadata": {
        "id": "Y1XNDFOrqxm1",
        "outputId": "234fe11e-e872-441d-dfbc-59848d242758",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2개 이상의 변수를 템플릿 안에 정의하는 것도 가능하다."
      ],
      "metadata": {
        "id": "6tOXnzbNrQcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"{area1}와 {area2}의 시차는 몇시간이야?\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "prompt"
      ],
      "metadata": {
        "id": "7UKfHPH3rVxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ],
      "metadata": {
        "id": "KIdklYmOrh4q"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(llm_chain.invoke({\"area1\": \"서울\", \"area2\": \"파리\"}))"
      ],
      "metadata": {
        "id": "zRa_8MiKrmeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_list = [\n",
        "    {\"area1\": \"파리\", \"area2\": \"뉴욕\"},\n",
        "    {\"area1\": \"서울\", \"area2\": \"하와이\"},\n",
        "    {\"area1\": \"켄버라\", \"area2\": \"베이징\"},\n",
        "]\n",
        "\n",
        "# 반복문으로 결과 출력\n",
        "result = llm_chain.apply(input_list)\n",
        "for res in result:\n",
        "    display(res[\"text\"].strip())"
      ],
      "metadata": {
        "id": "AUlKGqUprsfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "stream으로 출력도 가능하다만 OpenAI로 좀 다른거 같다. stream이란 함수를 호출해서 출력한다."
      ],
      "metadata": {
        "id": "fhMdyVyMsoNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0, #창의성\n",
        "    max_output_tokens=2048,\n",
        ")\n",
        "\n",
        "question = \"대한민국에 대해서 300자 내외로 최대한 상세히 알려줘\"\n",
        "\n",
        "for chunk in llm.stream(question):\n",
        "    display(to_markdown(chunk.content))\n",
        "    display(to_markdown(\"---\"))"
      ],
      "metadata": {
        "id": "4sR3ixAksq-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chain 생성에서 LCEL(LangChain Expression Language)도 가능한지 살펴본다."
      ],
      "metadata": {
        "id": "YSQtF6uiuBB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 주어진 나라에 대하여 수도를 묻는 프롬프트 템플릿을 생성합니다.\n",
        "template = \"\"\"\n",
        "당신은 친절하게 답변해 주는 친절 봇입니다. 사용자의 질문에 [FORMAT]에 맞추어 답변해 주세요.\n",
        "답변은 항상 한글로 작성해 주세요.\n",
        "\n",
        "질문:\n",
        "{question}에 대하여 설명해 주세요.\n",
        "\n",
        "FORMAT:\n",
        "- 개요:\n",
        "- 예시:\n",
        "- 출처:\n",
        "\"\"\"\n",
        "\n",
        "template = \"\"\"\n",
        "당신은 영어를 가르치는 10년차 영어 선생님입니다. 상황에 [FORMAT]에 영어 회화를 작성해 주세요.\n",
        "\n",
        "상황:\n",
        "{question}\n",
        "\n",
        "FORMAT:\n",
        "- 영어 회화:\n",
        "- 한글 해석:\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# OpenAI 챗모델을 초기화합니다.\n",
        "model = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-pro\",\n",
        "    google_api_key=GOOGLE_API_KEY,\n",
        "    temperature=0, #창의성\n",
        "    max_output_tokens=2048,\n",
        ")\n",
        "\n",
        "# 문자열 출력 파서를 초기화합니다.\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 프롬프트, 모델, 출력 파서를 연결하여 처리 체인을 구성합니다.\n",
        "chain = prompt | model | output_parser\n",
        "\n",
        "# 완성된 Chain 을 이용하여 country 를 '대한민국'으로 설정하여 실행합니다.\n",
        "# chain.invoke({\"country\": \"대한민국\"})\n",
        "print(chain.invoke({\"question\": \"저는 식당에 가서 음식을 주문하고 싶어요\"}))"
      ],
      "metadata": {
        "id": "NqSS-6PhuUin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.invoke({\"question\": \"미국에서 피자 주문\"}))"
      ],
      "metadata": {
        "id": "nTiI7hbmvl5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ebook에 있는 다른 예제도 실행해본다."
      ],
      "metadata": {
        "id": "fz-4MOAHv66A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt 를 PromptTemplate 객체로 생성합니다.\n",
        "prompt = PromptTemplate.from_template(\"{topic} 에 대해 쉽게 설명해주세요.\")\n",
        "\n",
        "# input 딕셔너리에 주제를 'ice cream'으로 설정합니다.\n",
        "input = {\"topic\": \"양자역학\"}\n",
        "\n",
        "# prompt 객체의 invoke 메서드를 사용하여 input을 전달하고 대화형 프롬프트 값을 생성합니다.\n",
        "prompt.invoke(input)\n",
        "\n",
        "# prompt 객체와 model 객체를 파이프(|) 연산자로 연결하고 invoke 메서드를 사용하여 input을 전달합니다.\n",
        "# 이를 통해 AI 모델이 생성한 메시지를 반환합니다.\n",
        "(prompt | model).invoke(input)"
      ],
      "metadata": {
        "id": "FuE8r61Hv9uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parse_output 메서드를 사용하여 AI 모델이 생성한 메시지 문자열로 출력합니다.\n",
        "display((prompt | model | output_parser).invoke(input))"
      ],
      "metadata": {
        "id": "KBkljGX_wIvE",
        "outputId": "8ff1d8af-a08a-42df-e41b-f5410f2521c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'**양자역학이란?**\\n\\n양자역학은 물질과 에너지의 매우 작은 규모에서의 행동을 설명하는 물리학의 한 분야입니다. 이는 원자와 그보다 작은 입자의 세계를 다룹니다.\\n\\n**양자역학의 주요 개념:**\\n\\n* **양자화:** 에너지, 각운동량, 전하와 같은 물리량은 특정 \"양자\" 또는 불연속적인 값만 가질 수 있습니다.\\n* **파동-입자 이중성:** 입자는 파동과 같은 성질을 가질 수 있으며, 파동은 입자와 같은 성질을 가질 수 있습니다.\\n* **불확정성 원리:** 입자의 위치와 운동량 또는 에너지와 시간을 동시에 정확하게 알 수 없습니다.\\n* **슈뢰딩거 방정식:** 입자의 파동 함수를 설명하는 방정식으로, 입자의 상태를 예측하는 데 사용됩니다.\\n* **파동 함수:** 입자의 상태를 설명하는 수학적 함수로, 입자의 위치, 운동량, 에너지와 같은 특성을 나타냅니다.\\n\\n**양자역학의 응용:**\\n\\n양자역학은 현대 기술의 기반이 되는 많은 응용 분야를 가지고 있습니다.\\n\\n* **레이저:** 양자역학적 효과를 이용하여 집중된 빛을 생성합니다.\\n* **트랜지스터:** 전자 기기의 기본 구성 요소로, 양자역학적 터널링 효과를 이용합니다.\\n* **MRI:** 인체의 내부 영상을 생성하는 의학적 기술로, 양자역학적 자기 공명 현상을 이용합니다.\\n* **양자 컴퓨팅:** 전통적인 컴퓨터보다 훨씬 더 강력한 컴퓨팅을 가능하게 하는 양자역학적 원리를 이용합니다.\\n\\n**양자역학의 이해:**\\n\\n양자역학은 직관에 어긋나는 개념을 많이 포함하고 있어 이해하기 어려울 수 있습니다. 그러나 이러한 개념은 물질과 에너지의 매우 작은 규모에서의 행동을 설명하는 데 필수적입니다. 양자역학은 현대 과학의 기본적인 기둥이며, 우리가 우주를 이해하는 방식에 혁명을 일으켰습니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LCEL 인터페이스에 있는 다른 내용은 필요할 때 보면 될 것 같고, 병렬성 예제를 돌려본다."
      ],
      "metadata": {
        "id": "EDuG92JIwqy-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# {country} 의 수도를 물어보는 체인을 생성합니다.\n",
        "chain1 = ChatPromptTemplate.from_template(\"{country} 의 수도는 어디야?\") | model\n",
        "\n",
        "# {country} 의 면적을 물어보는 체인을 생성합니다.\n",
        "chain2 = ChatPromptTemplate.from_template(\"{country} 의 면적은 얼마야?\") | model\n",
        "# 위의 2개 체인을 동시에 생성하는 병렬 실행 체인을 생성합니다.\n",
        "combined = RunnableParallel(capital=chain1, area=chain2)"
      ],
      "metadata": {
        "id": "gmhhArJ6w1No"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain1.invoke(\n",
        "    {\"country\": \"대한민국\"}\n",
        ")"
      ],
      "metadata": {
        "id": "nqfeWAwVxESf",
        "outputId": "cc604c27-532f-42c1-eba9-41ee8bc29989",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='서울', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-d25a85a7-3645-4f95-b5e4-8715b5392df2-0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain2.invoke({\"country\": \"미국\"})"
      ],
      "metadata": {
        "id": "urii-7RHxLed",
        "outputId": "3492c532-90c2-4618-a670-1c6eabb64762",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='9,833,517 평방 킬로미터', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-00ad4ec9-a3c8-444a-bf35-415b2377d317-0')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 주어진 'country'에 대해 'combined' 객체의 'invoke' 메서드를 호출합니다.\n",
        "combined.invoke({\"country\": \"대한민국\"})"
      ],
      "metadata": {
        "id": "N5080IAqxQMy",
        "outputId": "178d520f-a176-4ad4-b503-32cf355bfa16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'capital': AIMessage(content='서울', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-2b618781-b18a-4bf5-9158-ddffaed34132-0'),\n",
              " 'area': AIMessage(content='100,210 km²', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-72326469-a1a6-4091-848c-2706e888f4a5-0')}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    }
  ]
}